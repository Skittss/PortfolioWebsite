"use strict";(self.webpackChunkapp=self.webpackChunkapp||[]).push([[69],{78863:(e,t,i)=>{i.r(t),i.d(t,{default:()=>ne});i(27565);var a=i(6962),n=i(50899),s=i(42779),o=i(46761),r=i(20791),l=i(39432);const c=i.p+"static/media/Shimenawa_Night_1080p.600ae112ab660c489d8c.mp4";var h=i(57772);const d=i.p+"static/media/sunset_thumb.6b551ea5e11f5a2eb2d9.png",p=i.p+"static/media/night_thumb.0fa9b8c5c981cfda3b4d.png",m=i.p+"static/media/meiji.42550f4e24971935efd1.JPG",u=i.p+"static/media/sakurayama.74e81915139a27991b8f.JPG",f=i.p+"static/media/unknown_takayama.9bff702cdb1cbf26de5f.JPG",g=i.p+"static/media/fushimi_inari_1.b605bdf1c2ff6bc396e3.JPG",x=i.p+"static/media/fushimi_inari_2.6f5f2db65864eaa34449.JPG",w=i.p+"static/media/depth_map.30cf72cf9266fbaa3585.png",b=i.p+"static/media/domain_warp.7ffb40ea248cac81d989.webm",y=i.p+"static/media/rope_sdf_warping.5ca5cff7ab7da5436c37.png",j=i.p+"static/media/rope_sdf_no_coil.253c65c2d875d9f53381.png",v=i.p+"static/media/rope_sdf_one_coil.d53336c95d3afea5400b.png",A=i.p+"static/media/rope_sdf_two_coil.47dc362b90a06252bc25.png",_=i.p+"static/media/rope_sdf_complete.58829a849703a3ba9b26.png",S=i.p+"static/media/overshooting.afe3052b23e3537f0072.png",k=i.p+"static/media/normals.d0b5f7de0b3197a21159.png",T=i.p+"static/media/sphere_domain_rep.5cf995f8117dfb549652.png",N=i.p+"static/media/sphere_domain_rep_rad.3a5a7566b196338adb4a.png",L=i.p+"static/media/domain_rep_shimenawa.651b2e876f3688306891.png",F=i.p+"static/media/domain_rep_bridges.2470798d2e26ea425bd3.png",D=i.p+"static/media/domain_rep_pillars.a1874219936833930056.png",I=i.p+"static/media/hard_shadows.e649314039d1047ae917.png",E=i.p+"static/media/soft_shadows.b4f36a031f0ae1222113.png",C=i.p+"static/media/no-ao.b68bc5efea544fafa8f6.png",R=i.p+"static/media/no-ao-lambertian.007143be0bde3beed3fa.png",M=i.p+"static/media/ao-lambertian.80f87d505e36735b1d9d.png",O=i.p+"static/media/shadow_col_mult.9cb6d4057cb1c08d9275.png",W=i.p+"static/media/shadow_col_const_mix.43d00868ae0d85798064.png",B=i.p+"static/media/shadow_col_ambient_mix.8a062aa982632d7beb67.png",P=i.p+"static/media/shadow_col_ramped.bf7a70b66e9b8a25facd.png",$=i.p+"static/media/shadow_col_ramped_extra_bright.75dae6fe11a4fad5c337.png",q=i.p+"static/media/gloss_none.ce58557aa0899fa871a3.png",z=i.p+"static/media/gloss_fresnel.a6356ef1a5f060ae531c.png",H=i.p+"static/media/gloss_metallic.2479537bf266e717841c.png",G=i.p+"static/media/gloss_fresnel_metallic.1ec7749a37f746ea57c9.png",V=i.p+"static/media/sss_none.67145d19f38f4589565c.png",U=i.p+"static/media/sss_approx.5235730190ba38dfc20a.png",X=i.p+"static/media/login_screen.d1c6ce9099364cbaa7f8.png";i(73017);var J=i(8249),K=i(79346),Z=i(80651),Q=i(47738),Y=i(95569),ee=i(92026),te=i(27929);const ie=e=>{let{annotation:t,fontSize:i,...a}=e;const n=a.paddingBottom?a.paddingBottom:"20px";return(0,te.jsxs)("div",{style:{position:"relative"},children:[(0,te.jsx)("video",{...a,children:(0,te.jsx)("source",{src:a.src,type:"video/webm"})}),t?(0,te.jsx)("div",{className:"styled-text",style:{position:"absolute",bottom:0,left:0,backgroundColor:"rgba(21, 25, 31, 0.65)",width:"100%",fontSize:i&&i,textAlign:"center",padding:"10px 5px",paddingBottom:n},children:t}):null]})},{useBreakpoint:ae}=n.Ay,ne=()=>{const e=ae();return(0,te.jsxs)(Y.A,{title:Q.Meta.title,thumb:Q.Meta.teaser,githubURL:"https://github.com/Skittss/Shimenawa",projectLink:"https://www.shadertoy.com/view/clVyzW",children:[(0,te.jsx)("h1",{id:"overview",className:"raleway-title",children:"Overview"}),(0,te.jsx)("div",{style:{paddingBottom:"20px",textAlign:"center"},children:(0,te.jsx)("video",{style:{objectFit:"cover",width:"100%"},autoPlay:!0,loop:!0,muted:!0,children:(0,te.jsx)("source",{src:c,type:"video/mp4"})})}),(0,te.jsx)("p",{children:"'Shimenawa' is a non-photorealistically-rendered scene utilising ray marching to render complex implicit geometry and volumetrics. This means that everything you are looking at above is defined mathematically, and completely procedural!"}),(0,te.jsx)("p",{children:'Shimenawa ( \u6ce8\u2060\u9023\u2060\u7e04 ) - lit. "enclosing rope", is the main subject of the scene. The inspiration came to me following a recent trip to Japan where I was enamoured with the elegant aesthetic of cultural sites (\u795e\u2060\u793e - Shinto shrines), in which this rope - used as a talisman to ward against evil - is abundant.'}),(0,te.jsx)("br",{}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"500px"},children:[(0,te.jsx)(ee.A,{src:m,annotation:"Shimenawa at Meiji Shrine, Tokyo (\xa0\u660e\u2060\u6cbb\u2060\u795e\u2060\u5bab\u3001\u6771\u2060\u4eac\xa0)"}),(0,te.jsx)(ee.A,{src:u,annotation:"Shimenawa at Sakurayama Hachimingu Shrine, Takayama (\xa0\u6afb\u2060\u5c71\u516b\u2060\u5e61\u2060\u5bae\u3001\u9ad8\u2060\u5c71\xa0)"}),(0,te.jsx)(ee.A,{src:f,annotation:"Shimenawa and Colourful braided rope at an unknown shrine in Takayama (\xa0\u4e0d\u660e\u306e\u795e\u793e\u3001\u9ad8\u2060\u5c71\xa0)"}),(0,te.jsx)(ee.A,{src:g,annotation:"Shimenawa at Fushimi Inari, Kyoto (\xa0\u4f0f\u2060\u898b\u2060\u7a32\u2060\u8377\u5927\u2060\u793e\u3001\u4eac\u2060\u90fd\xa0)"}),(0,te.jsx)(ee.A,{src:x,annotation:"More shimenawa at Fushimi Inari, Kyoto (\xa0\u4f0f\u2060\u898b\u2060\u7a32\u2060\u8377\u5927\u2060\u793e\u3001\u4eac\u2060\u90fd\xa0)"})]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"The design of Shimenawa ropes varies by geographical region, and so I used the above photos I took as reference when designing it for the scene."}),(0,te.jsx)("p",{children:"The surrounding environment draws inspiration from Genshin Impact's main menu and 'slumbering court' locale for their wonderful stylised environment design."}),(0,te.jsx)("br",{}),(0,te.jsx)(o.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,te.jsx)("h1",{id:"renders",className:"raleway-title",children:"Renders"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:h,annotation:"Day"}),(0,te.jsx)(ee.A,{src:d,annotation:"Sunset"}),(0,te.jsx)(ee.A,{src:p,annotation:"Night"})]}),"To see the full shader in action, visit it on shadertoy ",(0,te.jsx)("a",{href:"https://www.shadertoy.com/view/clVyzW",target:"_blank",children:"here"}),", or through this embed (if your browser can load it, compile time is quite long):",(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{width:"100%",maxWidth:"540px",margin:"0 auto",aspectRatio:"3/2"},children:(0,te.jsx)("iframe",{width:"100%",height:"100%",frameborder:"0",src:"https://www.shadertoy.com/embed/clVyzW?gui=true&t=10&paused=true&muted=false",allowfullscreen:!0})}),(0,te.jsx)("br",{}),(0,te.jsx)(o.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,te.jsx)("h1",{id:"techniques",className:"raleway-title",children:"Techniques"}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"ray-marching",className:"raleway-title",children:"Ray Marching"}),(0,te.jsxs)("p",{children:["The algorithm at the core of this shader is sphere tracing, a simple yet versatile method when combined with Signed Distance Functions (SDFs). SDFs will be touched on more later, but the idea is to generate a camera ray, then render implicit geometry (i.e. a function ",(0,te.jsx)(J.A,{children:"$f(x,y,z)=0$"})," at an object's surface) by leaping forward in space repeatedly until we are close enough to the surface to say that it has been hit (i.e. below some epsilon bound). This then generates a t-value for the camera ray much like ray-tracing, but we have done so in an approximate, non-analytical manner."]}),(0,te.jsx)("p",{children:"The amount we leap forward in space should be proportional to the distance to the implicit surface to avoid overshooting. Luckily for us, SDFs are defined exactly as this distance, so naturally the following algorithm follows:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define MAX_STEPS 128\n#define EPSILON 0.001\nvoid mainImage(out vec4 fragColror, in vec2 fragCoord) {\n    vec3 ro = vec3(0.0); // camera origin\n    vec2 rd = getCameraRay(fragCoord);\n    \n    float t = 0.0;\n    for (int i=0; i<MAX_STEPS; i++) {\n        vec3 p = ro + t * rd; // a point along the ray\n        float d = map(p); // dist to surface\n        if (d < EPSILON) break;\n        t += d;\n    }\n\n    // We now have a t-value which allows us to render a basic image...\n    //   such as plot a depth-map, or do painter's algorithm, etc.\n}"})}),(0,te.jsx)("p",{children:"We will add complexity to this later, but even with this, we can already begin to render the geometry of our scene (by defining the map() function) with very little rendering code!"}),(0,te.jsx)(ee.A,{src:w,annotation:"Depth map of scene rendered only with the above rendering code as a basis"}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"sdf",className:"raleway-title",children:"Signed Distance functions (SDFs)"}),(0,te.jsx)("p",{children:"Signed distance functions define the distance to an implicit surface given a point in space. This can be an exact distance, or approximate, and is derived geometrically. The function will be zero-valued at the surface, positive when outside the surface, and negative inside."}),(0,te.jsxs)("p",{children:["Deriving SDFs can be challenging when they get complex, so generally we stick to using 'primitives' - simple yet powerful SDFs which we can combine together and distort to make any manner of shape we desire. ",(0,te.jsx)("a",{href:"http://iquilezles.org/articles/distfunctions/",children:"Inigo Quilez has an invaluable resource for definitions of many primitives"}),", as well as a more thorough explanation of SDFs in general. I thoroughly recommend you take a look. To get a basic idea however, we can very simply define the SDF for a sphere by observing that the closest point to the sphere lies along the vector from the point in space to the sphere origin, i.e:"]}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdSphere(in vec3 p, float r) {\n    return length(p) - r;\n}"})}),(0,te.jsx)("p",{children:"The following shader showcases a range of primitives that have reasonably mathematically simple definitions and can be used to construct more complex shapes via elementary set operations."}),(0,te.jsx)("div",{style:{width:"100%",maxWidth:"540px",margin:"0 auto",aspectRatio:"3/2"},children:(0,te.jsx)("iframe",{width:"100%",height:"100%",frameborder:"0",src:"https://www.shadertoy.com/embed/Xds3zN?gui=true&t=10&paused=true&muted=false",allowfullscreen:!0})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["The most simple operation we can define (and will make much use of) is the ",(0,te.jsx)("b",{children:"union"})," of two SDFs: simply ",(0,te.jsx)(J.A,{children:"$U(p)=\\text{min}(SDF_1(p), SDF_2(p))$"}),"."]}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"domain-transform",className:"raleway-title",children:"Simple Domain Transformations"}),(0,te.jsx)("p",{children:"You might have noticed with the sphere SDF code above that we never make a reference to the origin of the sphere. What's up with that? Surely we could only position objects at (0, 0, 0) if we defined them all like this?"}),(0,te.jsx)("p",{children:"And that is correct! ...At least until we employ domain transformations."}),(0,te.jsxs)("p",{children:["Domain transformations change the input space of our function, and not the function itself. For example, we can shift ",(0,te.jsx)("i",{children:"all"})," input points by an offset ",(0,te.jsx)("i",{children:"before"})," we evaluate the SDF to position it away from the origin. In turn we should note that we ",(0,te.jsx)("b",{children:"always evaluate an SDF as if it is centered at the origin for simplicity"}),"."]}),(0,te.jsxs)("p",{children:["This has some bearing on what transformation we should apply; if we want to shift a SDF in the ",(0,te.jsx)("b",{children:"positive"})," direction of the x axis for example, we should apply a ",(0,te.jsx)("b",{children:"negative"})," x transformation on the input space. This is because our SDF is ",(0,te.jsx)("b",{children:"still evaluated at the origin"}),", albeit in our new coordinate space."]}),(0,te.jsx)("p",{}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat map(in vec3 p) {\n    vec3 q = p - vec3(2.0, 0.0, 0.0); // q is our new coordinate space\n    // Note that we want the new origin to be at p=(2.0, 0.0, 0.0), so we should *subtract*\n    // so that is (0.0, 0.0, 0.0) at that point.\n\n    float d = sdSphere(q, 1.0);\n\n    return d;\n}"})}),(0,te.jsx)("p",{children:"The most useful transformation we can apply besides a domain shift is a domain rotation, which we should also quickly define. It is achieved the exact same way as a domain shift except with a rotation matrix applied instead of a simple vector subtraction:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define PI 3.1415926\n\nmat2 rot(in float a) { \n    float c = cos(a); float s = sin(a); \n    return mat2(c, s, -s, c); \n}\n\nfloat map(in vec3 p) {\n    vec3 q = p*rot(PI/2.0); // rotation in radians\n    float d = sdSphere(q, 1.0);\n\n    return d;\n}"})}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"warping",className:"raleway-title",children:"Domain Warping"}),(0,te.jsx)("p",{children:"We may wish to do a more complex transformation than a simple linear transformation of our input space. This is the role domain warping plays. Warping falls under the same umbrella as domain transformations, but we are specifically performing non-linear space transformations here."}),(0,te.jsx)("p",{children:"Warping is particularly useful when we want to add extra detail to an SDF without having to do a bunch of extra SDF calculations. Piling on many SDF calls is undesirable as it is the most expensive function in a complex scene. Instead we perturb the input space in clever ways to mimic a fine level of detail."}),(0,te.jsx)("p",{children:"In this scene, I mainly use domain warping for two things: construction of the rope SDF, and object animation."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Animation is fairly straight forward; we can create simple procedural animations by perturbing based on a time factor. Even better - slap the perturbation into a periodic function like sin or cosine, and you have a perfect loop with little effort! The animation below is a simple time-based and periodic radial peturbation of the y coordinate space."}),(0,te.jsx)(ie,{annotation:"Exaggerated domain warping applied for animation of the rope (\u6ce8\u9023\u7e04) and wind on the paper (\u7d19\u5782)",src:b,style:{objectFit:"cover",width:"100%"},autoPlay:!0,loop:!0,muted:!0}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Next let's look at the rope SDF itself."}),(0,te.jsx)(ee.A,{src:y,annotation:"Shimenawa SDF (with materials & lighting applied)"}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Though this SDF looks complicated, it is in fact a rather simple construction! The reality is that it is actually just two simple cylindrical capsules rotated and bent around a circle. Let's have a look at each step:"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:j,annotation:"Start with a simple capsule lying on the x-axis"}),(0,te.jsx)(ee.A,{src:v,annotation:"Offset rotation dependent on the x-axis coordinate"}),(0,te.jsx)(ee.A,{src:A,annotation:"Duplicate the coil and mirror in xz plane (vertically, though really just orthogonal to the rotation offset)"}),(0,te.jsx)(ee.A,{src:_,annotation:"Loop into a torus shape"})]}),(0,te.jsx)("p",{children:"Simple enough once it's broken down, right? Though this is conceptually easy to understand, how do we technically and mathematically implement each step above?"}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"1. x-axis aligned capsule"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"This is self explanatory once you have the SDF for a capsule, which can be thought of as the SDF of an elongated sphere:"]}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdCapsule(vec3 p, float r, float h) {\n    p.x -= clamp(p.x, 0.0, h);\n    return length(p) - r;\n}"})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"2. Offset rotation dependent on the x-coordinate"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"The aim of this step is to set up the repeating braided structure of the rope. If you were to make such a rope in real life, you would braid it by twisting coils around one another - so let's take inspiration and do exactly that with maths!"]}),(0,te.jsxs)("p",{children:["'twisting' is simply rotation where we rotate more and more as we go further down the rope. This is where the x-coordinate of the capsule comes in. It corresponds to how much rotation we should do at each point. We must also ",(0,te.jsx)("i",{children:"offset"})," the rotation, or else we will rotate the capsule in-place (it is rotationally symmetrical) and percieve no difference. Let's start with that:"]}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRopeCoil(vec3 p, in float braid_r, in float l, in float rot_freq, in float rot_offset)\n{\n    // Rotate and twist a capsule to make the rope along the x axis\n    p.yz *= rot(p.x * PI * rot_freq); // twisting; 45-deg per x\n    p.y -= rot_offset; // offset for rotation\n    float d = sdVerticalCapsule(p, braid_r, l);\n\n    return d;\n}"})}),(0,te.jsx)("p",{children:"Note that we rotate in the yz plane as it is orthogonal to the x-axis which the rope lies upon."}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"3. Duplicating the coil"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"At this stage, the rope lacks a second coil and thus the volume and physicality of an actual rope. There are computationally efficient ways to duplicate our SDFs (",(0,te.jsx)(a.Vq,{smooth:!0,to:"#repetition",children:"Domain Repetition"}),"), but for now let's keep it simple and just evaluate the SDF twice:"]}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRope(vec3 p, in float braid_r, in float l, in float rot_freq, in float rot_offset)\n{\n    float d = 1e10; // initialise distance;\n    d = min(d, sdRopeCoil(p, braid_r, l, rot_freq,  rot_offset)); // Top coil\n    d = min(d, sdRopeCoil(p, braid_r, l, rot_freq, -rot_offset)); // Bot coil\n\n    return d;\n}"})}),(0,te.jsx)("p",{children:"Now we have something that distinctly looks like rope, which we can then loop to get the desired effect."}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"4. Looping into a torus"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"Looping the straight coil into a torus shape can be done in a few ways, but my approach was to use a special kind of domain transformation involving conversion between two local coordinate spaces."]}),(0,te.jsx)("h3",{id:"local-uvs",className:"raleway-title",children:"Imposing SDFs with local UVs"}),(0,te.jsx)("p",{children:"By converting between coordinate spaces, we can impose one shape onto another. The following demo shows this technique in 2D with an arrow SDF imposed onto that of a circle. This is the same effect that we want to create for the rope, but in 2d."}),(0,te.jsx)("div",{style:{width:"100%",maxWidth:"540px",margin:"0 auto",aspectRatio:"3/2"},children:(0,te.jsx)("iframe",{width:"100%",height:"100%",frameborder:"0",src:"https://www.shadertoy.com/embed/mtGcDz?gui=true&t=10&paused=true&muted=false",allowfullscreen:!0})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"For our purposes, transforming the SDF around one base axis is sufficient. This same technique is extensible to any transformation, but let's keep it simple for now."}),(0,te.jsx)("p",{children:"For the rope coils (or in the above demo, the arrow), the base axis is simply the axis which the SDF lies along, in this case x. For the circle, we can view the base axis as lying along the circumference of the circle. Keeping track of the distance along the circumference will thus give us this axis coordinate (t), so let's make that SDF quickly:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdCircle(in vec2 p, in float r, out float t) \n{\n    // angle to closest pt in range [-PI, PI]\n    float closest_p_theta = atan(p.y, p.x) + PI;\n    t = closest_p_theta / (2.0 * PI); // convert to range [0, 1]\n    \n    return length(p) - r;\n}"})}),(0,te.jsx)("p",{children:"Now that we have a mapping between the coordinates of the base axis, let's think about how we convert between the other (orthogonal) axis."}),(0,te.jsx)("p",{children:"For the SDF we are imposing onto the circle, this axis is unchanged. In our 2D example it is simply the y axis. For the circle itself, this axis changes radially, and is in fact given by the distance to the circle, which is the result of the SDF! This property also generalises to the local coordinate space of any SDF if you think about it."}),(0,te.jsx)("p",{children:"Now we have a basic example for imposing SDFs onto one another:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdImpose(in vec2 p, in float r)\n{\n    float rt = 0.0f;\n\tfloat d = sdCircle(p, r, rt);\n\n    // adjust 0 -> 1 t-value to actual circumference of the circle\n    vec2 segUV = vec2(rt * 2.0*PI*r, d); // calculate local uv\n    d = sdArrow(segUV, ...arrow params); // Arrow lying on x-axis\n\n    return d;\n}"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Next is applying this to our 3D example. The problem actually remains unchanged as the circle we want to impose the rope onto still lies on a 2D plane. Our third axis (y) remains constant between our coordinate spaces, so we only have to make slight modifications for it to work in 3D:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRope(vec3 p, in float braid_r, in float l) {\n    float rt = 0.0;\n    float d = sdCircle(p.xz, r, rt);\n    float circum = 2.0*PI*r;\n    \n    vec3 ring_uvw = vec3(rt * circum, p.y, d);\n    d = sdRope(ring_uvw, r, circum, 10.0, 0.02);\n\n    return d;\n}"})}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"overshooting",className:"raleway-title",children:"Overshooting in Warping"}),(0,te.jsx)("p",{children:"If you implement the code above, you might notice that it doesn't quite look right. Certain parts of the object may appear to clip into nothingness - what's happening here?"}),(0,te.jsx)(ee.A,{src:S,annotation:"What's happening to my SDF?!"}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Let's look at what happens to our SDF when we warp the domain to see what's going on:"}),(0,te.jsx)("div",{style:{width:"100%",maxWidth:"540px",margin:"0 auto",aspectRatio:"3/2"},children:(0,te.jsx)("iframe",{width:"100%",height:"100%",frameborder:"0",src:"https://www.shadertoy.com/embed/4fSXDV?gui=true&t=10&paused=true&muted=false",allowfullscreen:!0})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["We can see that in some cases (the peaks of the sin wave) the warped SDF ends up closer to the sample point than our distance describes. The result when we apply this to ray marching is ",(0,te.jsx)("i",{children:"overshooting"})," - we end up missing the surface entirely because we have ",(0,te.jsx)("b",{children:"overestimated the distance"})," to it."]}),(0,te.jsx)("p",{children:"The simplest solution to overshooting is to simply multiply the SDF distance by a constant factor:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRope(vec3 p, in float braid_r, in float l) {\n    ...\n\n    d *= 0.8; // const for fixing overshooting\n    return d;\n}"})}),(0,te.jsx)("p",{children:"This ensures our distance is conservative so no overshooting can occur. The exact factor you need to use depends on how extreme the warp is."}),(0,te.jsx)("p",{children:"We must be mindful of the effect this has on performance, however. Underestimating the distance to an object will make us perform more raymarching steps than normal when we render it. For example, if we approximate the distance as half of what it should be, we will end up reaching the surface in twice the amount of raymarching steps. This solves the overshooting problem, but this 2x operation multiplier can slow the program down and be the difference between a useable one, and an unusable one in the context of real-time rendering."}),(0,te.jsxs)("p",{children:["Therefore, we should keep this constant ",(0,te.jsx)("b",{children:"as large as possible"})," and ",(0,te.jsx)("b",{children:"apply it on an individual basis to only warped objects which have overshooting problems"}),", not the entire raymarching loop."]}),(0,te.jsx)("p",{children:"Additionally, a lot of the time overshooting problems will be unnoticeable or nonexistant if the warp is small, so we should use this fix with prudence."}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"repetition",className:"raleway-title",children:"Domain Repetition and Scaling Scenes"}),(0,te.jsx)("p",{children:"We now have a way to modify basic primitives with transformations and warping, and are able to fix them when they break."}),(0,te.jsxs)("p",{children:["This is great - we can start to make some more complex scenes with lots of geometry by re-calling our SDF functions at different points in space and performing a union with ",(0,te.jsx)(J.A,{children:"$\\min()$"}),". However, when we do this, we will quickly notice that it runs quite poorly. The reasons for this are at least twofold:"]}),(0,te.jsxs)("div",{style:{paddingLeft:"2vw",paddingRight:"2vw"},children:[(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsxs)(l.A,{className:"project-style-cont",children:[(0,te.jsx)("b",{children:"1. "})," \xa0\xa0\xa0"]}),(0,te.jsxs)(l.A,{className:"project-style-cont",flex:"1vw",children:["Our scene ",(0,te.jsx)(J.A,{children:"$\\text{map}()$"})," function becomes overly coupled between lots of unrelated geometry."]})]}),(0,te.jsx)("br",{}),(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsxs)(l.A,{className:"project-style-cont",children:[(0,te.jsx)("b",{children:"2. "})," \xa0\xa0\xa0"]}),(0,te.jsx)(l.A,{className:"project-style-cont",flex:"1vw",children:"Lots of repeated calls to the same expensive SDF function."})]}),(0,te.jsx)("br",{})]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"First, let's address 1. What do I mean by this?"}),(0,te.jsxs)("p",{children:["When we lump all of our scene geometry into one big SDF - ",(0,te.jsx)(J.A,{children:"$\\text{map}()$"}),", we are forced into evaluating the SDF for our entire scene even when we are only considering calculations for a single object. This is especially notable when we add expensive lighting calculations into the mix (as we will encounter in the next couple of sections)."]}),(0,te.jsxs)("p",{children:["Think about casting shadows on objects for example; we currently would be forced to evaluate the effect of ",(0,te.jsx)("i",{children:"all"})," objects casting a shadow on the object we're actually considering at a point ",(0,te.jsx)(J.A,{children:"$p$"}),". While this is an accurate calculation, it is undoubtedly slow - the complexity of lighting our scene will scale polynomially with respect to the number of objects in it."]}),(0,te.jsxs)("p",{children:["Instead, if we know that certain objects can ",(0,te.jsx)("i",{children:"never interact"}),", or the effect of this being the case is unnoticeable, we should separate them into different functions so we have more control over what SDFs we evaluate for certain calculations. This in turn allows us to scale up our scene without hemorrhaging performance."]}),(0,te.jsxs)("p",{children:["A simple separation we can make is between ",(0,te.jsx)("b",{children:"background and foreground"}),". We can get away with having less detail in a background, so it makes sense to not couple it with calculations for the foreground, which tend to be much more expensive."]}),(0,te.jsxs)("p",{children:["If you look at the code for Shimenawa, I split the SDFs, normal and lighting calculations, and even the raymarching itself into separate ",(0,te.jsx)(J.A,{children:"$\\text{...Foreground}()$"})," and ",(0,te.jsx)(J.A,{children:"$\\text{...Background}()$"})," functions to save on performance."]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We've now found a better way of dealing with point no. 1, so now on to 2."}),(0,te.jsx)("p",{children:"Currently (as we've seen with our rope example) if we want to duplicate an object, we simply make another call to the SDF:"}),(0,te.jsx)("p",{children:(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRope(vec3 p, in float braid_r, in float l, in float rot_freq, in float rot_offset)\n{\n    float d = 1e10; // initialise distance;\n    d = min(d, sdRopeCoil(p, braid_r, l, rot_freq,  rot_offset)); // Top coil\n    d = min(d, sdRopeCoil(p, braid_r, l, rot_freq, -rot_offset)); // Bot coil\n\n    return d;\n}"})})}),(0,te.jsxs)("p",{children:["But isn't this sort of wasteful? The calls to the SDF are ",(0,te.jsx)("i",{children:"exactly the same"}),", so wouldn't it be great if there were some way of condensing this into a single call to increase performance?"]}),(0,te.jsx)("p",{children:"Enter domain repetition! Domain repetition refers to dividing our infinite spatial domain into repetitions of finite space. We first map a point in infinite space into a finite local space, then evaluate the SDF. So long as our SDFs lie within the bounds of the finite spaces, we have gotten away with rendering as many duplications of an object as we want with zero additional SDF overhead."}),(0,te.jsx)("p",{children:"It is worth noting that although we eliminate SDF overhead, we still make the render more expensive, but in an efficient way. We still have to do more material / lighting calculations as we render objects for more pixels than before. No free lunch, eh?"}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"This may seem a little hand-wavey at first, so let's first apply this to our example with the rope, noting that our duplicated object is simply a reflection in the xz plane:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdRope(vec3 p, in float braid_r, in float l, in float rot_freq, in float rot_offset)\n{\n    float d = 1e10; // initialise distance;\n    p.y = abs(p.y) - 0.02; // domain repetition: reflection in xz\n    d = min(d, sdRopeCoil(p, braid_r, l, rot_freq,  rot_offset));\n\n    return d;\n}"})}),(0,te.jsx)("p",{children:"Note that we have to offset the SDF in y in order for it to be duplicated in entirety. We have effectively partitioned our input space into two (reflected) partitions along the XZ plane."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We can partition our space for repetition in any arbitrary way we like. For example, by partitioning space with a 2D grid:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdDomainRepGrid(vec3 p)\n{\n    float d = 1e10; // initialise distance;\n\n    const vec2 spacing = vec2(145.0); // grid spacing\n    vec2 id = round(p.xz / spacing); // index of the current tile p is in\n\n    vec2 q = p; // local grid space coord\n\n    // Have a quick think about why the following transform works\n    //    (Hint: SDFs are evaluated at the world-space origin)\n    q.xz = p.xz - spacing * id; // transform to local grid space\n\n    d = sdSphere(q, 2.5); // render spheres - only one SDF call!\n\n    return d;\n}"})}),(0,te.jsx)(ee.A,{src:T,annotation:"Infinite domain repetition of spheres via a grid"}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Another useful example is a radial repetition:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define TAU 6.28318533\nfloat sdDomainRepRad(vec3 p)\n{\n    float d = 1e10; // initialise distance;\n\n    vec3 q = p;\n    const float rep_angle = TAU / 7.0; // angle of repetition sector (7 sectors)\n    float sector round(atan(p.z, p.x) / rep_angle);\n    float rot_angle = sector * rep_angle;\n    q.xz *= rot(angrot);\n\n    // Have a quick think about why this offset is necessary\n    q.x -= 1.0; // offset the SDF from the origin\n\n    d = sdSphere(q, 0.05);\n\n    return d;\n}"})}),(0,te.jsx)(ee.A,{src:N,annotation:"Radial domain repetition of spheres"}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We've really only scratched the surface of what domain repetition is able to do with these two examples, but rest assured it is a powerful tool for making the illusion that a scene is complex when it is in fact rather simple and inexpensive."}),(0,te.jsx)("p",{children:"Let's look at a few examples of how I applied domain repetition in Shimenawa:"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:L,annotation:"Rotational repetition used to duplicate the hanging ropes and paper."}),(0,te.jsx)(ee.A,{src:F,annotation:"1D grid repetition used to duplicate bridge segments into a single continuous bridge."}),(0,te.jsx)(ee.A,{src:D,annotation:"2D grid repetition and warping used to arrange duplicated pillar segments in a pseudo-random fashion."})]}),(0,te.jsx)("p",{children:"As well as these examples, I used domain repetition extensively in modelling to make complex yet inexpensive implicit geometry."}),(0,te.jsxs)("p",{children:["I highly recommend ",(0,te.jsx)("a",{href:"https://iquilezles.org/articles/sdfrepetition/",target:"_blank",children:"Inigo Quilez' resources on domain repetition"})," if you are interested in using domain repetition for yourself. There are lots of different ways to apply it - for example, think about how you may limit our infinite grid example to a ",(0,te.jsx)("i",{children:"finite"})," grid. All manner of these examples are explained thoroughly in the aforementioned article."]}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"accel",className:"raleway-title",children:"Acceleration Structures"}),(0,te.jsx)("p",{children:"As our scene becomes very complex, it becomes increasingly beneficial to cut down on the work we do in rendering SDFs in certain cases."}),(0,te.jsx)("p",{children:"For particularly expensive SDFs that take up a large proportion of our scene, we can gain a good amount of performance back by employing acceleration techniques."}),(0,te.jsxs)("p",{children:["For Shimenawa, I used three such techniques: ",(0,te.jsx)("b",{children:"Bounding Volumes"}),", ",(0,te.jsx)("b",{children:"Level of Detail (LOD)"}),", and ",(0,te.jsx)("b",{children:"Culling"}),"."]}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"1. Bounding Volumes"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"This reduces the work done to render a complex SDF by only evaluating the whole (expensive) SDF when we are marching close to it. At larger distances, we evaulate a single inexpensive SDF for a volume that bounds it. For example:"]}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nfloat sdExample(vec3 p)\n{\n    float d = 1e10;\n\n    // Evaluate bbox if > 1.0 away\n    const float bbox_eval_dist = 1.0;\n\n    // Bounding box\n    d = sdBox(p, ...); // params defined per-object to fit\n    if (d > bbox_eval_dist) return 1e10;\n\n    // Only evaluate the expensive SDF if we are close\n    return sdExampleExpensive(p);\n}"})}),(0,te.jsx)("p",{children:"It is worth noting that with ray marching, we end up doing more marching steps as we are close to objects to converge on the final distance value for a pixel. This means that we usually do a fairly high number of evaulations of the expensive SDF anyway as we march close, somewhat negating the improvements from the bounding box. Nevertheless, this is still a good improvement for very expensive geometry."}),(0,te.jsx)("p",{children:"It is preferable to use a scaled primitive from an expensive SDF as the bounding box instead of an additional, unrelated SDF. This removes the bounding box overhead entirely, making this optimisiation a no-brainer to implement."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Importantly, we can also apply a bounding volume to the ray marching loop itself. This is extremely effective at increasing performance as we effectively reduce the resolution of our scene into only the areas that have objects, instead of wasting work evaluating SDFs for pixels we know will have no geometry."}),(0,te.jsx)("p",{children:"This is a very simple addition to our main ray marching loop, provided we can analytically intersect the bounding volume (in the following case, a sphere):"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define MAX_STEPS 128\n#define EPSILON 0.001\n#deinfe BOUNDING_SPHERE_SIZE = 10.0\nvoid mainImage(out vec4 fragColror, in vec2 fragCoord) {\n    vec3 ro = vec3(0.0); // camera origin\n    vec2 rd = getCameraRay(fragCoord);\n    \n    // In (x), out (y) intersection points of the bounding volume\n    vec2 bounding_isect = iSphere(ro, rd, BOUNDING_SPHERE_SIZE);\n\n    // If there is an intersection, and the volume currently visible\n    if (bounding_isect.y > 0.0) {\n        // We can even start the ray march at the edge of the bounding volume\n        float t = max(bounding_isect.x, EPSILON);\n\n        for (int i=0; i<MAX_STEPS; i++) {\n            vec3 p = ro + t * rd; // a point along the ray\n            float d = map(p); // dist to surface\n            if (d < EPSILON) break;\n            t += d;\n        }\n    }\n}"})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"2. Level of Detail (LOD)"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"For extremely expensive SDFs, we may have a lot of fine detail which becomes almost impossible to discern at far distances. It therefore doesn't make sense for us to be doing a lot of work for something that ultimately goes unseen. LOD refers to creating a less-expensive version of the thing we want to render, and rendering it in place of the expensive version when it is sufficiently far away from the camera. In the case of SDFs, we can just remove the primitives used for fine detail and redefine it as a separate function."]}),(0,te.jsx)("p",{children:"In Shimenawa, I implemented this for the infinite bridges, as the fine details will always become aliased and unnoticeable as the bridge stretches to infinity."}),(0,te.jsx)("p",{children:"In code, it may look something like this:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define LOD_DIST 100.0\nfloat sdExample(vec3 p)\n{\n    // Note this assumes the camera is at the world origin.\n    bool use_lod = length(p) > LOD_DIST;\n\n    float d = use_lod ? sdExampleLOD(p): sdExampleExpensive(p);\n\n    return d;\n}"})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("b",{children:(0,te.jsx)("u",{children:"3. Culling"})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),"We can reduce work in the ray march itself by terminating it early when we know that we are never going to intersect a certain object. This can either be because we have defined it in a certain way or that we simply do not care that certain portions are not rendered. This is usually because a) we have defined our SDFs in such a way that we know the cannot exist in certain portions of space. Or b) the parts of the object which are culled are not visible anyway."]}),(0,te.jsx)("p",{children:"We must be aware that if we forcibly terminate the raymarch, nothing will be rendered behind the object we culled, including objects from different SDFs which may exist somewhere along the ray."}),(0,te.jsx)("p",{children:"In Shimenawa, I used culling mostly for the field of pillars, as it was extremely costly to render. The pillars are culled in the y axis below a certain height they are enveloped in clouds. Additionally, the pillars are culled after a certain distance from the origin to make the scene less cluttered and less expensive."}),(0,te.jsx)("p",{children:"Implementing culling is as simple as early-exiting your SDF before it is evaluated depending on a certain factor, for example vertical height:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define Y_CULL 10.0\nfloat sdCullExample(vec3 p)\n{\n    // Cull based on y\n    if (p.y > Y_CULL) return 1e10;\n\n    return expensiveSDF(p);\n}"})}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"normals",className:"raleway-title",children:"Calculating Normals of Implicit Geometry"}),(0,te.jsx)("p",{children:"There are a couple different ways to approach calculating normals for implicit geometry. The one that I (and many others on shadertoy) use is a variant of central differences which samples from a tetrahedron."}),(0,te.jsx)("p",{children:"The basic idea of central differences is analogous to how we calculate a vertex normal - we look at the surfaces adjacent to the sample point to determine the derrivative (which is the normal)."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Mathematically, we calculate the partial derivatives in each primary axis to get the derivative of the surface:"}),(0,te.jsx)("div",{style:{fontSize:e.sm?"inherit":12,paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\displaystyle \\nabla f(p) = \\bigg\\lbrace{\\partial f(p)\\over \\partial x}, {\\partial f(p)\\over \\partial y}, {\\partial f(p)\\over \\partial z}\\bigg\\rbrace$"})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["Each partial derivative is then approximated via central difference, where ",(0,te.jsx)(J.A,{children:"$h$"})," defines our interval size (smaller is more accurate):"]}),(0,te.jsxs)("div",{style:{fontSize:e.sm?"inherit":12},children:[(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\displaystyle {\\partial f(p)\\over \\partial x} \\approx \\frac{f(p + \\lbrace h, 0, 0\\rbrace) - f(p - \\lbrace h, 0, 0\\rbrace)}{2h}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\displaystyle {\\partial f(p)\\over \\partial y} \\approx \\frac{f(p + \\lbrace 0, h, 0\\rbrace) - f(p - \\lbrace 0, h, 0\\rbrace)}{2h}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\displaystyle {\\partial f(p)\\over \\partial z} \\approx \\frac{f(p + \\lbrace 0, 0, h\\rbrace) - f(p - \\lbrace 0, 0, h\\rbrace)}{2h}$"})})]}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["Central difference is generally preferred for accuracy over the forward difference which you were probably taught in calculus class ",(0,te.jsx)(J.A,{children:"$\\big(f(p + \\lbrace h, 0, 0\\rbrace) - f(p) / h\\big)$"})," as it is not directionally biased."]}),(0,te.jsxs)("p",{children:["It is worth noting though that we end up doing 6 evaluations of ",(0,te.jsx)(J.A,{children:"$f(p)$"})," for central differences, whereas the forward difference needs only 4. This is undesirable when ",(0,te.jsx)(J.A,{children:"$f$"})," is our expensive SDF."]}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["By sampling points on a tetrahedron, we can get the best of both worlds: central difference accuracy with only 4 ",(0,te.jsx)(J.A,{children:"$f$"})," evaluations."]}),(0,te.jsx)("p",{children:"The vertices of the tetrahedron are given by:"}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$k_0=\\begin{Bmatrix}\\phantom{-}1 & -1 & -1\\end{Bmatrix}\\\\ k_1=\\begin{Bmatrix}-1 & -1 & \\phantom{-}1\\end{Bmatrix} \\\\ k_2=\\begin{Bmatrix}\\phantom{-}1 & -1 & -1\\end{Bmatrix} \\\\ k_3=\\begin{Bmatrix}\\phantom{-}1 & \\phantom{-}1 & \\phantom{-}1\\end{Bmatrix}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"The property that none of these vertices lie directly on a primary axis allows us to sum the function at each vertex to give the derivative via the following derivation:"}),(0,te.jsx)("div",{style:{fontSize:e.sm?"inherit":10,margin:"0 auto",width:"fit-content",paddingLeft:"3em",paddingRight:"3em",textAlign:"left"},children:(0,te.jsx)(J.A,{children:"$\n                    \\displaystyle \\phantom{\\iff}m=\\sum_ik_if(p+hk_i)\\\\\n                    \\iff m=\\sum_ik_i(f(p+hk_i) - f(p))\\\\\n                    \\iff m=\\sum_ik_i\\nabla_{k_i}f(p)\\\\\n                    \\iff m=\\sum_ik_i(k_i\\cdot\\nabla f(p))\\\\\n                    \\iff m=\\nabla f(p)\\cdot\\bigg\\lbrace\\sum_i k_{i_x}k_i,\\ \\sum_i k_{i_y}k_i,\\ \\sum_i k_{i_z}k_i\\bigg\\rbrace\\\\\n                    \\iff m= 4\\ \\nabla f(p)\\\\~\\\\\n                    \\ \\implies \\bar n = {m\\over |m|}\n                $"})}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["I highly suggest reading ",(0,te.jsx)("a",{href:"http://iquilezles.org/articles/normalsSDF/",target:"_blank",children:"this article from Inigo Quilez"})," for a more thorough explanation of this derivation."]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We don't have to understand this whole derivation to put the resulting observation into code:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\nvec3 calcNormal(vec3 p) {\n    const float h = 1e-5;\n    const vec2 k = vec2(1, -1);\n    return normalize( k.xyy * map(p + k.xyy) + \n                      k.yyx * map(p + k.yyx) +\n                      k.yxy * map(p + k.yxy) +\n                      k.xxx * map(p + k.xxx) );\n}"})}),(0,te.jsx)("p",{children:"And just like that, we have normals!"}),(0,te.jsx)(ee.A,{src:k,annotation:"Visualisation of normals generated for an SDF using tetrahedron sampling."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Though the above code works perfectly fine mathematically, you may encounter examples which look different yet identical at runtime."}),(0,te.jsx)("p",{children:"The reason for this is due to how certain compilers deal with the above code. Particularly for WebGL, the compiler may decide to inline the map function four times in an attempt to boost runtime performance, but in doing so, may dramatically increase the compile time, or may run over the allowed instruction size on the platform itself."}),(0,te.jsx)("p",{children:"Some solutions (particularly on shadertoy) trick the compiler into leaving the function be by changing the normal calculation into a loop. The loop must depend on a value which is unknown at runtime to prevent the loop from being unwound and causing a similar problem to before."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Now with normals calculated, we have all the geometric information we need to move on to lighting! :)"}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"shadows",className:"raleway-title",children:"Fast Soft Shadows"}),(0,te.jsxs)("p",{children:["The calculations most integral to grounding our scene revolve around the transportation of light. Though our use of light does not have to be physically correct, it is usually a important to ",(0,te.jsx)("i",{children:"base our lighting from physical principles"}),". This makes our calculations more well defined and, importantly, lets us avoid the \"uncanny valley\" where things 'just don't look quite right'."]}),(0,te.jsx)("p",{children:"In this section and the next we will look at methods to build up a simple lightscape. We will focus at this stage on splitting our image into occluded / non-occluded parts through use of shadow."}),(0,te.jsx)("p",{children:"To preface, light transportation is more complicated than a simple occlusion pass, and we will deliberately be leaving out specific light phenomena like bounce lighting (indirect illumination), and subsurface scattering here to revisit later mostly in the interest of performance."}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"The most basic approach we will begin with is by casting a shadow similar to how it is done in ray tracing. That is, we cast a ray from an objects surface in the direction of light, evaluating the colour as shadow if we intersect any objects on the way."}),(0,te.jsx)("p",{children:"The obvious way to implement this is with a secondary ray marching loop:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define MAX_SHADOW_STEPS 256\nvoid calcShadow(in vec3 ro, in vec3 rd) {\n\n    // Start with a small t offset to avoid reintersecting the current surface\n    float t = 0.01;\n\n    // No shadow unless an intersection happens during the raymarch\n    //   Note: Shadow is a multiplier on colour, so 1.0 = no shadow, 0.0 = full shadow.\n    float shadow = 1.0;\n\n    for (int i=0; i<MAX_SHADOW_STEPS; i++) {\n        vec3 p = ro + t * rd;\n        float d = map(p);\n\n        if (d < EPSILON) { shadow = 0.0; break; };\n\n        t += d;\n    }\n\n    return shadow;\n}"})}),(0,te.jsx)(ee.A,{src:I,annotation:"Hard shadows via a secondary ray-march"}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:["This is a good starting point, but is not the look that we're going for. We have reduced shadowing to a binary case, when real shadows almost never look this sharp unless we are in very strong (almost always unnatural) lighting conditions. Not to say that this way of shadowing is 'incorrect' - we could definitely use it for a comic style or in ",(0,te.jsx)("a",{href:"https://en.wikipedia.org/wiki/Cel_shading",target:"_blank",children:"cel shading"}),"."]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"For more realistic shadows, we must observe that shadows have regions of partial occlusion - penumbra - where our shadow multiplier will be somewhere between zero and one. This is due to light sources having a physical size, not just being some abstract and infintessimally small point. From a given perspective, a proportion of the light source may be occluded, so we should model this also."}),(0,te.jsx)("p",{children:"SDFs become very beneficial in doing so. What would normally take ray-tracing many individual samples to compute, we can approximate by observing that at any point along our light ray if we are close to hitting an object, then we are likely in the penumbra. We can also surmise that the amount of occlusion is inversely proportional to the distance to the nearest intersection, which is exactly what the SDF describes. Lastly we can assume that the distance along the light ray is proportional to the occlusion due to the effects of parallax."}),(0,te.jsx)("p",{children:"From this, we can come up with the following equation:"}),(0,te.jsx)("div",{style:{margin:"0 auto",width:"fit-content",paddingLeft:"3em",paddingRight:"3em",textAlign:"left"},children:(0,te.jsx)(J.A,{children:"$\\displaystyle \\phantom{\\iff} \\text{occ}\\propto {t \\over d}\\\\~\\\\ \\iff\\text{occ}= k \\cdot {t \\over d}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Then modify our existing shadow calculation to use it:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define MAX_SHADOW_STEPS 256\nvoid calcShadow(in vec3 ro, in vec3 rd, float k) {\n\n    float t = 0.01;\n\n    // Again, default case is no shadow\n    //  Note: shadow = 1 - occ so it can be used as a multiplier\n    float shadow = 1.0;\n\n    for (int i=0; i<MAX_SHADOW_STEPS; i++) {\n        vec3 p = ro + t * rd;\n        float d = map(p);\n        \n        // early exit for full shadow\n        if (d < EPSILON) return 0.0;\n\n        // Note: flip occ calculation as shadow is inv. proportional to occ.\n        shadow = min(shadow, k * d / t)\n\n        t += d;\n    }\n\n    return shadow;\n}"})}),(0,te.jsx)(ee.A,{src:E,annotation:"Soft shadows, k = 2.0"}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"For Shimenawa, I chose to make the foreground shadows softer than those in the background to mimic the light scattering properties you may see from a rope material. While the sunlight remains the same for the entire scene, a rope would internally scatter the light somewhat due to gaps and subsurface scattering, leading to an overall more diffuse look. Instead of modelling this complex scattering, just increasing the shadow softness is enough to get the point across."}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"In cases, there is minor artifacting with the approach above. If this becomes an issue, I would recommend looking at the following fix (it is worth noting that this fix is more expensive though)."}),(0,te.jsx)("div",{style:{width:"100%",maxWidth:"540px",margin:"0 auto",aspectRatio:"3/2"},children:(0,te.jsx)("iframe",{width:"100%",height:"100%",frameborder:"0",src:"https://www.shadertoy.com/embed/lsKcDD?gui=true&t=10&paused=true&muted=false",allowfullscreen:!0})}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"ao",className:"raleway-title",children:"Ambient Occlusion"}),(0,te.jsx)("p",{children:"We've generated a simple lightscape with shadow casting, but you may have noticed that our result still looks a bit flat. For example with the rope, wouldn't we expect the crevices between the two braids to be dark? As it stands, these areas are fully illuminated."}),(0,te.jsxs)("p",{children:['The first reason for this is our very basic use of materials. Currently, our material is a single colour, or "albedo", for all parts not in shadow. Typically, we will model the amount of light which would reach a surface at a certain point within the material itself. This is called ',(0,te.jsx)("b",{children:"diffuse lighting"}),", and we typically implement it as ",(0,te.jsx)("i",{children:"lambertian diffuse"}),", the details of which will follow in the next section."]}),(0,te.jsxs)("p",{children:["We should also note that diffuse lighting is ",(0,te.jsx)("b",{children:"not the same as the shadow casting we did in the previous step"}),". We do not model inter-object lighting, only intra-object lighting (i.e. self-shadowing). However, implementing this will lead to some visual improvement:"]}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:C,annotation:"Without lambertian diffuse (for comparison)"}),(0,te.jsx)(ee.A,{src:R,annotation:"With lambertian diffuse"})]}),(0,te.jsx)("p",{children:"Lambertian diffuse is one part of the equation for getting more accurate lighting, but the aforementioned problem with crevices being fully illuminated is still unsolved."}),(0,te.jsxs)("p",{children:["This is because the rest of the problem is actually a ",(0,te.jsx)("i",{children:"global illumination"})," issue. We should think about ",(0,te.jsx)("i",{children:"why"})," a crevice would be less illuminated - because ambient light is less likely to bounce into the crevice then back into our camera. Importantly, this is not necessarily direct light from our light source, so we must find another way to model ",(0,te.jsx)("i",{children:"indirect"})," lighting outside of our shadow pass."]}),(0,te.jsx)("p",{children:"This is the role of ambient occlusion (AO). We model how likely it is that light would arrive at a point on the model's surface, and use that to determine our final colour alongside our shadow multiplier. It follows that if light is less likely to arrive at a point, the final colour should be darker."}),(0,te.jsx)("p",{children:'AO approximates the probability of light reaching a point by sampling for nearby geometry that may occlude the point. With this description, it should be more obvious why the technique is called "ambient occlusion" in the first place.'}),(0,te.jsx)("p",{children:"More specifically, we uniformly sample points in a hemisphere about the surface normal. This is an approach you will be familiar with if you've done ray tracing before. Let's have a look at it in code:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define AO_SAMPLES 64.0\n#define AO_MAX_SAMPLE_DIST 0.01\n#define AO_DISTANCE_FALLOFF 6.0\nvoid calcAO(in vec3 p, in vec3 normal) {\n\n    float ao = 0.0;\n\n    for (int i=0; i<int(AO_SAMPLES); i++) {\n        \n        vec3 sample_vector = sampleHemisphere(float(i), AO_SAMPLES);\n\n        // Sample at random distances as we are really sampling a volume of space\n        float h = hash(float(i));\n        sample_vector *= AO_MAX_SAMPLE_DIST * h;\n        \n        vec3 q = p + 0.01 * normal; // Point just above the surface to avoid self-sampling.\n        \n        // Any points at a distance > 1.0 are not close enough to contribute to the occlusion\n        ao += clamp(map(q + sample_vector), 0.0, 1.0);\n    }\n    ao /= AO_SAMPLES;\n\n    // Control the linear falloff of the AO\n    return clamp(ao * AO_DISTANCE_FALLOFF, 0.0, 1.0);\n}"})}),(0,te.jsx)("p",{children:"The basic loop is very simple; we sample from the hemisphere, and accumulate the distance to the closest object, taking the average at the end. Our AO is a multiplier like with our shadow calculation, so full occlusion and no occlusion are 0.0 and 1.0 respectively."}),(0,te.jsx)("p",{children:"I haven't included the sampleHemisphere() function here - see if you can work through it yourself. It involves some reasonably simple maths with spherical coordinates."}),(0,te.jsxs)("p",{children:["Finally, note the inclusion of a hashing function at line 13. With AO, we are really sampling the entire volume of space about our point for occlusion, not just a shell. This is important as we are using SDFs, which only give the distance from a given point, not along a ray like we may have in ray tracing. Thus, we include a hashing function (",(0,te.jsx)(a.Vq,{smooth:!0,to:"#hash",children:"details here"}),") to generate a [0, 1] value for each sample which we can use to ensure we sample at varying distances."]}),(0,te.jsx)("p",{children:"With AO included, we get a much better lighting approximation:"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:R,annotation:"Lambertian diffuse only (for comparison)"}),(0,te.jsx)(ee.A,{src:M,annotation:"Ambient Occlusion and lambertian diffuse"})]}),(0,te.jsx)("p",{children:"With just shadow casting and AO, we have a relatively simple yet already powerful lighting system. This suffices most of our lighting needs, the rest of which we can tackle individually for each material as we see fit, like with our lambertian diffuse example above."}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"materials",className:"raleway-title",children:"Stylised Material System"}),(0,te.jsx)("p",{children:"Though materials have been used up until this point, I havent gone into the details of how they are implemented. Shimenawa uses a basic yet heavily stylised material system. The only material property that I chose to define is material albedo (base colour) - the rest of the material properties are handled on a case-by-case basis when calculating lighting."}),(0,te.jsx)("p",{children:"We can define a material per SDF evaluation by returning (or passing in and setting an out/pointer argument) alongside our distance value. By doing this, we can define per-instance materials so that duplicates of the same object may be rendered with different colours and lighting effects. Take for example the paper hanging from the rope ( \u7d19\u5782 ) where per instance materials are used to change the colour of individual paper strips from red to white above."}),(0,te.jsx)("p",{children:"Managing materials at a high level in this way requires a system to map a numerical value we return from the SDF to a certain material; an enum is a good choice for this. GLSL does not have an enum wrapper, but we can achieve the same effect by defining our enum values as macros:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define MAT_0 1.0\n#define MAT_1 2.0\n#define MAT_2 3.0\n//...\n#define MAT_DEBUG 1e10"})}),(0,te.jsx)("p",{children:"It is a good idea to include a default/debug material for convenience and debugging purposes in case your material index becomes messed up as you implement more rendering features."}),(0,te.jsx)("p",{children:"We can now start evaluating object colour in our render loop with branching logic:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n// We could directly compare material values with equality, but using\n//  a helper macro like the following is more versataile.\n#define CMP_MAT_LT(a, b) a < (b + 0.5)\n\nvec3 render(in vec3 ro, in vec3 rd, in float t, in float m) \n{\n    // Calculate properties and lighting effects that all materials use\n    vec3 normal = calcNormal(pos);\n    float shadow = calcShadow(ro, rd);\n    float ambient_occlusion = calcAO(p, normal);\n\n    vec3 col = vec3(0.0);\n    \n    // Select material based on cascading comparisons of m to material values\n    if (CMP_MAT_LT(m, MAT_0)) {\n        // ...Calculate colour and lighting properties of MAT_0\n    }\n    else if (CMP_MAT_LT(m, MAT_1)) {\n        // ...Calculate colour and lighting properties of MAT_1\n    } \n    else if (CMP_MAT_LT(m, MAT_2)) {\n        // ...Calculate colour and lighting properties of MAT_2\n    }\n    else {\n        // ...Debug / Default material\n    }\n\n    return col;\n}"})}),(0,te.jsx)("p",{children:"Due to materials generally generally being quite localised and thus usually in the same shader group, the hit on performance from branching like this is fairly inconsequential."}),(0,te.jsx)("p",{children:"With the high-level material system set up, we can move onto applying stylised effects to individual materials."}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"stylised-lighting",className:"raleway-title",children:"Simple Stylised Lighting"}),(0,te.jsx)("p",{children:"The first basic step in applying lighting to a material is to mix the material's albedo with the occlusion values we calculated earlier. We can start by combining the occlusion values multiplicatively and applying then to the material's albedo."}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{occ} = \\text{shadow} \\times \\text{ao}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$(\\text{i})\\ \\text{col} = \\text{occ} \\times \\text{albedo}$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Improving this slightly, we can mix in a shadow colour to our albedo based on the value of occ."}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{col} = \\text{mix}(\\text{shadow\\_col},\\ \\text{albedo},\\ \\text{occ})$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We could choose all manner of values for the shadow colour, but drawing from and modifying physical principles is usually a good start when we want to stlyise. Let's consider a few to build up a stylised lighting model - if you are aware of the phong lighting model, our starting point will be similar."}),(0,te.jsx)("p",{children:"When light is occluded in reality, a proportion of the total light energy will be reflected back into view, so we can start by modelling the shadow colour in this way:"}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{shadow\\_col} = \\text{mat\\_ occ} \\times \\text{albedo}\\ | \\ \\text{mat\\_occ}\\in [0,1]$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\implies\\text{(ii)}\\ \\text{col} = \\text{mix}(\\text{mat\\_ occ} \\times \\text{albedo},\\ \\text{albedo},\\ \\text{occ})$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"It is a good idea to separate this occlusion value into a separate variable 'mat_occ' so that we have more artistic control over per material lighting. A shadow colour defined in this way effectively incorporates a constant strength ambient light into the scene."}),(0,te.jsx)("p",{children:"We can take this even further and actually incorporate an ambient light colour into the shadow colour, akin to global illumination. This should be a colour from the scene's environment to ground the lighting in reality. When rendering outdoor scenes, some variant of the sky colour is a good choice:"}),(0,te.jsx)("div",{style:{fontSize:e.sm?"inherit":12,paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{shadow\\_col} = \\text{mix}(\\text{mat\\_occ} \\times \\text{albedo},\\ \\text{mat\\_ambient},\\ \\text{ambient})\\ | \\ \\text{ambient}\\in [0,1]$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("div",{style:{fontSize:e.sm?"inherit":12,paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\implies\\text{(iii)}\\ \\text{col} = \\text{mix}\\bigg(\\text{mix}(\\text{mat\\_occ} \\times \\text{albedo},\\ \\text{mat\\_ambient},\\ \\text{ambient}),\\ \\text{albedo}, \\text{occ}\\bigg)$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"We can see how these methods compare:"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:O,annotation:"Shadow applied via (i) - multiplicative"}),(0,te.jsx)(ee.A,{src:W,annotation:"Shadow applied via (ii) - constant mix"}),(0,te.jsx)(ee.A,{src:B,annotation:"Shadow applied via (iii) - constant & ambient mix"})]}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"shadow-ramp",className:"raleway-title",children:"Colour Ramps"}),(0,te.jsx)("p",{children:"A particular effect that I wanted to incorporate on the rope in Shimenawa was sub-surface scattering."}),(0,te.jsx)("p",{children:"Sub-surface scattering describes the transport of light within a translucent or porous object. It is the same effect that you get when you can see your skin glow when you shine a torch on it for example, or why marble sculptures tend to look 'soft' or have a subtle glow. The same effect would be present on the rope when the sun shines at it - leading to a distinct glow around the edges of the rope where rope fibers would be sparse."}),(0,te.jsx)("p",{children:"Though there is an upcoming section about applying this to a simpler case: the hanging paper, computing this effect for the rope accurately would be too expensive, or cheaply would be too inaccurate to resemble the desired feature."}),(0,te.jsxs)("p",{children:["An alternative solution I came up with is to use a combination of colour ramps, ",(0,te.jsx)(a.Vq,{smooth:!0,to:"#bloom",children:"bloom"}),", and ",(0,te.jsx)(a.Vq,{smooth:!0,to:"#outline",children:"stylised object outlines"}),". The usage of colour ramps was inspired by the lighting in Genshin Imapct, as well as their Unite Seoul 2018 talk: ",(0,te.jsx)("a",{href:"https://youtu.be/egHSE0dpWRw?si=_hTHBpRsOviCzsmK&t=776",target:"_blank",rel:"noreferrer",children:"From mobile to high-end PC: Achieving high quality anime style rendering on Unity"}),"."]}),(0,te.jsx)("p",{children:"Colour ramps define a multi-colour gradient over a value range, I use this both to boost contrast of lighting, as well as to add a artificial sub-surface scattering component when desired. We can generate simple colour ramps along shadow edges by using the already calculated occlusion factor as our value range."}),(0,te.jsx)("p",{children:"The artificial subsurface scattering component is calculated by mixing a highly saturated 'terminator line' colour into a material's shadow colour as follows:"}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{ramped\\_shadow\\_col} = \\text{mix}\\bigg(\\text{shadow\\_col},\\ \\text{terminator\\_col},\\allowbreak\\ \\min(1.0,\\ 4.0 \\times \\text{occ})\\bigg)$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"The coefficient 4.0 of 'occ' is discretionary and serves to make the colour ramp shallower or steeper, depending on the desired effect. Typically, terminator lines in sub-surface scattering are fairly sharp, so I chose to use a relatively steep ramp here."}),(0,te.jsx)("p",{children:"We can then boost the lighting contrast by similarly applying a ramp to the albedo-shadow mix function:"}),(0,te.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{(iv)}\\ \\text{col} = \\text{mix}\\bigg(\\text{ramped\\_shadow\\_col},\\allowbreak\\ \\text{albedo},\\ \\min(1.0,\\ 2.0 \\times \\text{occ})\\bigg)$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Applying this contrast ramp has a side effect of making the shadows particularly dark, so as a result I decided to modify the occlusion combination to brighten dark spots and make ambient occlusion more emphasised:"}),(0,te.jsx)("div",{style:{fontSize:e.sm?"inherit":12,paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,te.jsx)(J.A,{children:"$\\text{(v)}\\ \\displaystyle\\text{occ} = \\frac{\\text{shadow} + \\text{extra\\_shadow\\_brightness}}{1.0 + \\text{extra\\_shadow\\_brightness}} \\times \\text{ao}^2$"})}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"The effect is subtle, but has noticeable effects from certain viewing angles."}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:P,annotation:"Shadow applied via (iv) - ramped"}),(0,te.jsx)(ee.A,{src:$,annotation:"Shadow applied via (v) - ramped and brightened"})]}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"reflections",className:"raleway-title",children:"Grazing angles and Metallic Reflections"}),(0,te.jsx)("p",{children:"For certain materials, such as metals and smooth surfaces (as well as dielectrics), a specular lighting component can be incorporated to add a sheen or glossiness to the material."}),(0,te.jsxs)("p",{children:["Two mathematical concepts we can use to implement this are ray reflection, and the fresnel effect. We can calculate fresnel simply as ",(0,te.jsx)(J.A,{children:"$\\vec n\\cdot \\vec {d}$"}),", where d is the ray direction, and ray reflection using GLSL's inbuilt ",(0,te.jsx)(J.A,{children:"$\\text{reflect()}$"})," function."]}),(0,te.jsx)("p",{children:"For simple smooth surfaces, including fresnel in the lighting calculation will add a nice sheen at shallow ('grazing') viewing angles which sufficiently creates the illusion of smoothness for our scene."}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n// ...From MAT_0 branch: Example values for a smooth/glossy material\n#define MAT_0_ALBEDO vec3(0.9, 0.7, 0.5)\n#define MAT_0_OCC 0.2\n#define MAT_0_AMBIENT vec3(0.9, 0.9, 0.8)\n#define MAT_0_AMBIENT_COEFF 0.2\n#define MAT_0_FRESNEL vec3(0.7, 0.8, 0.9)\n\n// Calculate fresnel and translate to range [0,1]\nfloat fresnel = clamp(1.0 + dot(normal, rd), 0.0, 1.0); // glossy component\n\nvec3 shadow_col = mix(MAT_0_OCC * MAT_0_ALBEDO, MAT_0_AMBIENT, MAT_0_AMBIENT_COEFF);\nvec3 albedoFresnel = MAT_0_ALBEDO + fresnel * MAT_0_FRESNEL;\nvec3 col = mix(shadow_col, albedoFresnel, occ);\n"})}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:q,annotation:"No Fresnel Applied"}),(0,te.jsx)(ee.A,{src:z,annotation:"Fresnel Applied"})]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"For metals, we can incorporate both fresnel and a specular component calculated similarly to how a specular component is calculated in the phong lighting model:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n// ...From MAT_0 branch: Example values for a metallic material\n#define MAT_0_ALBEDO vec3(0.9, 0.7, 0.5)\n#define MAT_0_OCC 0.2\n#define MAT_0_AMBIENT vec3(0.8, 0.9, 0.9)\n#define MAT_0_AMBIENT_COEFF 0.2\n#define MAT_0_FRESNEL vec3(0.7, 0.8, 0.9)\n#define MAT_0_SPECULAR vec3(0.9)\n#define LIGHT_DIR vec3(-1.0)\n\n// Calculate fresnel and translate to range [0,1]\nfloat fresnel = clamp(1.0 + dot(normal, rd), 0.0, 1.0); // glossy component\n\n// Calculate reflection and attenuate\nfloat reflection = dot(rd, reflect(LIGHT_DIR, normal)) // metallic component\nreflection = smoothstep(0.5, 0.6, reflection)\n\nvec3 shadow_col = mix(MAT_0_OCC * MAT_0_ALBEDO, MAT_0_AMBIENT, MAT_0_AMBIENT_COEFF);\nvec3 albedoMetallic = MAT_0_ALBEDO + fresnel * MAT_0_FRESNEL + reflection * MAT_0_SPECULAR;\nvec3 col = mix(shadow_col, albedoMetallic, occ);\n"})}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:q,annotation:"No Metallic Reflections Applied"}),(0,te.jsx)(ee.A,{src:H,annotation:"Metallic Reflections Applied"})]}),(0,te.jsxs)("p",{children:["The difference here is that we can ",(0,te.jsx)(J.A,{children:"$\\text{smoothstep}$"})," the reflective component to attenutate the specular component. Smoothstepping between a small value range as above gives a focused, cel-shading like highlight akin to a smooth metal, whereas a large value range would give the appearance of a rougher metal."]}),(0,te.jsx)("br",{}),(0,te.jsx)("p",{children:"Combining both leads to a simple yet pleasing lighting visual:"}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:q,annotation:"No Effects"}),(0,te.jsx)(ee.A,{src:G,annotation:"Glossy & Metallic Effects"})]}),(0,te.jsxs)("p",{children:["It is worth noting that in our highly stylised scene, there is no one ",(0,te.jsx)("i",{children:"correct"})," way of calculating our lighting, we can make any approximations we like if they look good! There are many more intricate examples from PBR that would be more accurate to reality, but the above examples are merely that - examples which I found looked good for my use case :)"]}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"sss",className:"raleway-title",children:"Quick Sub-surface Scattering Approximation"}),(0,te.jsx)("p",{children:"The final technique I will touch on here is a simple and very rough sub-surface scattering approximation which works well for objects which are convex, fairly geometrically uniform, and uniformly dense."}),(0,te.jsxs)("p",{children:["My implementation here is based off of the following GDC talk: ",(0,te.jsx)("a",{href:"https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/",target:"_blank",rel:"noreferrer",children:"GDC 2011 - Approximating Translucency for a Fast, Cheap and Convincing Subsurface Scattering Look"}),", so please refer here if you would like more details!"]}),(0,te.jsx)("p",{children:"The basic idea is to calculate an additive SSS colour by doing a cheap secondary ray cast from an intersection point on a SSS enabled material in the direction of (important) light sources. The ray cast gives the distance that light travels through an object to be visible from the sample point. If we then assume uniform density, we can linearly attenuate the light based on this distance to generate an approximate SSS light colour."}),(0,te.jsx)("p",{children:"Since all our geometry is defined by SDFs, we can skip the raycast and instead do a single additional SDF evaluation to get the distance value. This requires us to bump the sample point however so we don't just constantly sample a zero-value of the SDF. Bumping proportionally to our ray march t-value is a simple and effective solution:"}),(0,te.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,te.jsx)(K.A,{language:"cpp",showLineNumbers:!0,style:Z.A,startingLineNumber:0,children:"\n#define SSS_COEFF 1.0\n#define SSS_COL vec3(0.9)\n\n// 1/5 is our proportionality constant which defines how far\n//  away a light source will effect our SSS calculation.\nfloat transmission_range = t / 5.0; \nfloat transmission = map(pos + LIGHT_DIR * transmission_range) / transmission_range;\n\n// Calculate SSS, smoothstepping transmission to make sure the value does not explode\nvec3 sss = SSS_COEFF * SSS_COL * smoothstep(0.0, 1.0, transmission);\n\n// Regular material lighting calculation\nvec3 shadow_col = ...\nvec3 albedo = ...\nvec3 col = sss + mix(shadow_col, albedoMetallic, occ);\n"})}),(0,te.jsxs)(s.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%"},children:[(0,te.jsx)(ee.A,{src:V,annotation:"No SSS Applied to Hanging Paper"}),(0,te.jsx)(ee.A,{src:U,annotation:"Simple SSS Applied to Hanging Paper"})]}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"volumetrics",className:"raleway-title",children:"Volumetric Cloud Rendering"}),(0,te.jsx)("p",{children:"The 'above the clouds' cloudscape in Shimenawa is inspired by the fabulously designed log-in screen from Genshin Impact."}),(0,te.jsx)(ee.A,{src:X,annotation:"Genshin Impact's login screen: Inspiration for Shimenawa's Cloudscape"}),(0,te.jsx)("br",{}),(0,te.jsxs)("p",{children:[(0,te.jsx)("a",{href:"https://youtu.be/-JFyAdI_rO8?si=Za0ttWcJ5J4TATBL&t=1473",taget:"_blank",rel:"noreferrer",children:"MiHoYo's talk at GDC 2021"})," outlines that their cloud rending tech works on a artist-controlled layered billboard system, responsible for its distinctive flat-drawn feel."]}),(0,te.jsx)("p",{children:"For Shimenawa, our main render loop is already driven by ray-marching though, so we can more easily integrate a fancier ray-marching algorithm for participating media into the scene, which we will be doing in this section."}),(0,te.jsxs)("p",{children:["The cloud rendering tech used was inspired by the tech used in ",(0,te.jsx)("a",{href:"https://www.guerrilla-games.com/read/the-real-time-volumetric-cloudscapes-of-horizon-zero-dawn",target:"_blank",rel:"noreferrer",children:"Horizon: Zero Dawn"}),". This tech has been revised and generally improved with a voxel-based approach given the release of ",(0,te.jsx)("a",{href:"https://advances.realtimerendering.com/s2023/index.html#Nubis3",target:"_blank",rel:"noreferrer",children:"Horizon: Forbidden West"}),", so I'd love to revisit the algorithm presented here in a future project."]}),(0,te.jsx)("p",{children:"Before giving this section a read though, I strongly recommend having a look at the following resources, which I myself used during implementation. This should alleviate some of the burden with the technical language about to follow."}),(0,te.jsxs)("div",{style:{paddingLeft:"2vw",paddingRight:"2vw"},children:[(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsx)(l.A,{className:"project-style-cont",children:"\xa0\xa0\xa0\xa0\xa0"}),(0,te.jsx)(l.A,{className:"project-style-cont",flex:"1vw",children:(0,te.jsxs)("li",{children:[(0,te.jsx)("b",{children:"Geurilla Games: The Real time volumetric cloudscapes of Horizon: Zero Dawn."})," ",(0,te.jsx)("a",{href:"https://www.guerrilla-games.com/read/the-real-time-volumetric-cloudscapes-of-horizon-zero-dawn",target:"_blank",rel:"noreferrer",children:"[Publication]"})," ",(0,te.jsx)("a",{href:"https://advances.realtimerendering.com/s2015/The%20Real-time%20Volumetric%20Cloudscapes%20of%20Horizon%20-%20Zero%20Dawn%20-%20ARTR.pdf",target:"_blank",rel:"noreferrer",children:"[PDF]"})]})})]}),(0,te.jsx)("br",{}),(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsx)(l.A,{className:"project-style-cont",children:"\xa0\xa0\xa0\xa0\xa0"}),(0,te.jsx)(l.A,{className:"project-style-cont",flex:"1vw",children:(0,te.jsxs)("li",{children:[(0,te.jsx)("b",{children:"Sebastien Hillaire: Phsyically Based Sky, Atmosphere and Cloud Rendering in Frostbite."})," ",(0,te.jsx)("a",{href:"https://www.ea.com/frostbite/news/physically-based-sky-atmosphere-and-cloud-rendering",target:"_blank",rel:"noreferrer",children:"[Publication]"})," ",(0,te.jsx)("a",{href:"https://media.contentapi.ea.com/content/dam/eacom/frostbite/files/s2016-pbs-frostbite-sky-clouds-new.pdf",target:"_blank",rel:"noreferrer",children:"[PDF]"})]})})]}),(0,te.jsx)("br",{}),(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsx)(l.A,{className:"project-style-cont",children:"\xa0\xa0\xa0\xa0\xa0"}),(0,te.jsx)(l.A,{className:"project-style-cont",flex:"1vw",children:(0,te.jsxs)("li",{children:[(0,te.jsx)("b",{children:"Fredrik Haggstrom: Real-time rendering of volumetric clouds."})," ",(0,te.jsx)("a",{href:"http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1223894&dswid=-695",target:"_blank",rel:"noreferrer",children:"[Publication]"})," ",(0,te.jsx)("a",{href:"http://www.diva-portal.org/smash/get/diva2:1223894/FULLTEXT01.pdf",target:"_blank",rel:"noreferrer",children:"[PDF]"})]})})]}),(0,te.jsx)("br",{}),(0,te.jsxs)(r.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,te.jsx)(l.A,{className:"project-style-cont",children:"\xa0\xa0\xa0\xa0\xa0"}),(0,te.jsx)(l.A,{className:"project-style-cont",flex:"1vw",children:(0,te.jsxs)("li",{children:[(0,te.jsx)("b",{children:"PBR: From theory to implementation, Section 11."})," ",(0,te.jsx)("a",{href:"https://www.pbr-book.org/4ed/Volume_Scattering",target:"_blank",rel:"noreferrer",children:"[Publication]"})]})})]})]}),(0,te.jsx)("br",{}),(0,te.jsx)("br",{}),(0,te.jsx)("h3",{id:"volum-ray-march",className:"raleway-title",children:"Ray Marching Volumetrics"}),(0,te.jsx)("p",{children:"In our regular ray marching loop, we assume that radiance is constant along the whole length of the ray. For volumetrics, we cannot make this assumption as the transmission of light varies depending on certain characteristics, such as the medium's density and what portion of the visible light spectrum is absorbed by the material within."}),(0,te.jsx)("p",{children:"Thus, the overarching idea behind ray marching volumetrics is to use the ray marching steps to accumulate varying radiance samples along the ray, leading to a final reflected radiance value."}),(0,te.jsx)("p",{children:"Radiance along the ray may come directly from a light source, or from light scattered within the volume. In addition, light can be absorbed as it scatters throughout, or scatter out of the volume entirely. We must take all of these characteristics into account as we sample if we wish to render a convincing volumetric."}),(0,te.jsx)("h3",{id:"volum-blue-noise",className:"raleway-title",children:"Approximate Sampling and Blue Noise"}),(0,te.jsx)("p",{children:"The following sections are a work in progress, please come back later!"}),(0,te.jsx)("h3",{id:"volum-shape",className:"raleway-title",children:"Shaping the Clouds"}),(0,te.jsx)("h3",{id:"volum-shape-noise",className:"raleway-title",children:"Perlin-Worley Noise"}),(0,te.jsx)("h3",{id:"volum-lighting",className:"raleway-title",children:"Lighting the Clouds"}),(0,te.jsx)("h3",{id:"volum-multiple-octaves",className:"raleway-title",children:"Multiple Octave Scattering"}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"hdr",className:"raleway-title",children:"HDR Rendering"}),(0,te.jsx)("h3",{id:"bloom",className:"raleway-title",children:"Buffer-pass Bloom"}),(0,te.jsx)("br",{}),(0,te.jsx)("h2",{id:"ldr",className:"raleway-title",children:"LDR Post-processing"}),(0,te.jsx)("h2",{id:"bonus",className:"raleway-title",children:"Bonus: Some Extra Techniques"}),(0,te.jsx)("h3",{id:"fog",className:"raleway-title",children:"Better Fog"}),(0,te.jsx)("h3",{id:"hash",className:"raleway-title",children:'"Good Enough" Hashing'}),(0,te.jsx)("h3",{id:"atmosphere",className:"raleway-title",children:"Simple Atmospheres"}),(0,te.jsx)("h3",{id:"stars",className:"raleway-title",children:"Procedural Star Fields"}),(0,te.jsx)("h3",{id:"outline",className:"raleway-title",children:"Stylised Object Outlines"}),(0,te.jsx)("h3",{id:"dithering",className:"raleway-title",children:"Cheap Dithering"})]})}},92026:(e,t,i)=>{i.d(t,{A:()=>s});i(27565);var a=i(45577),n=i(27929);const s=e=>{let{annotation:t,fontSize:i,...s}=e;const o=s.paddingBottom?s.paddingBottom:"20px";return(0,n.jsxs)("div",{style:{position:"relative"},children:[(0,n.jsx)(a.A,{...s}),t?(0,n.jsx)("div",{className:"styled-text",style:{position:"absolute",bottom:0,left:0,backgroundColor:"rgba(21, 25, 31, 0.65)",width:"100%",fontSize:i&&i,textAlign:"center",padding:"10px 5px",paddingBottom:o},children:t}):null]})}},58990:(e,t,i)=>{i.d(t,{A:()=>d});var a=i(27565),n=i(11030),s=i(20477),o=i(58860),r=i(46761),l=i(75342),c=i(85477),h=(i(29780),i(27929));const d=e=>{let{title:t,githubURL:i,projectRoute:d,projectLink:p,thumb:m}=e;const u=(0,n.zy)().pathname;return(0,a.useEffect)((()=>{window.scrollTo(0,0)}),[]),(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("div",{style:{marginTop:"-3rem",backgroundImage:"url(".concat(m,")"),backgroundPosition:"center",backgroundSize:"cover",backgroundRepeat:"no-repeat",height:"100vh",zIndex:-1}}),(0,h.jsxs)("div",{className:"project-home-wrapper",style:{position:"absolute",width:"100%",top:"101vh",left:"0px",transform:"translate(0, -100%)"},children:[(0,h.jsxs)("header",{className:"home-header",children:[(0,h.jsx)("h1",{id:"title",style:{display:"inline-block"},children:t}),(0,h.jsxs)("span",{style:{padding:"0 1em",display:"inline-block"},children:[void 0!=i?(0,h.jsx)(o.A,{title:"View on Github",placement:"bottom",children:(0,h.jsx)("a",{href:i,target:"_blank",children:(0,h.jsx)(l.A,{className:"title-icon"})})}):null,void 0!=d?(0,h.jsx)(o.A,{title:"View project",placement:"bottom",children:(0,h.jsx)(s.N_,{to:u+d,children:(0,h.jsx)(c.A,{className:"title-icon"})})}):null,void 0!=p?(0,h.jsx)(o.A,{title:"View project",placement:"bottom",children:(0,h.jsx)("a",{href:p,target:"_blank",children:(0,h.jsx)(c.A,{className:"title-icon"})})}):null]}),(0,h.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}})]}),(0,h.jsx)("div",{style:{height:"8em"}})]})]})}},95569:(e,t,i)=>{i.d(t,{A:()=>g});var a=i(28370),n=i.n(a),s=i(58990),o=i(65894),r=i(9514),l=i(27565),c=i(27929);const h=e=>{var t=e.filter((e=>{let t=e.nodeName;return"title"!==e.id&&("H1"===t||"H2"===t||"H3"===t)}));let i=-1;var a=t.map((e=>(i++,{key:"contents_".concat(i),href:"#".concat(e.id),title:e.innerHTML,level:parseInt(e.nodeName.slice(-1))}))),n=[],s=[],o=[n];return a.forEach((e=>{var t=s.findIndex((t=>t>=e.level));-1===t?t=s.push(e.level)-1:s.length=t+1,o[t].push(Object.assign({},e,{children:o[t+1]=[]}))})),n},d=e=>{let{title:t}=e;const{nestedHeadings:i}=(()=>{const[e,t]=(0,l.useState)([]);return(0,l.useEffect)((()=>{const e=Array.from(document.querySelectorAll("h1, h2, h3")),i=h(e);t(i)}),[]),{nestedHeadings:e}})(),{navHeight:a}=(()=>{const[e,t]=(0,l.useState)(0);return(0,l.useEffect)((()=>{const e=document.getElementById("main-navbar");console.log(e),t(e.offsetHeight)}),[]),{navHeight:e}})(),[n,s]=(0,l.useState)("85vh");return(0,l.useEffect)((()=>{const e=document.getElementById("toc-breadcrumb");e&&s("calc(100vh - 6rem - ".concat(e.offsetHeight,"px)"))}),[]),(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(o.A,{id:"toc-breadcrumb",style:{paddingBottom:"14px",position:"sticky"},items:[{title:(0,c.jsx)("a",{href:"#home",children:"Portfolio"})},{title:(0,c.jsx)("a",{href:"#projects",children:"Projects"})},{title:"".concat(t)}]}),(0,c.jsx)(r.A,{style:{maxHeight:n,overflow:"auto"},targetOffset:a,onClick:(e,t)=>{e.preventDefault()},items:i})]})};var p=i(50899),m=i(20791),u=i(39432);const{useBreakpoint:f}=p.Ay,g=e=>{let{title:t,thumb:i,projectLink:a,projectRoute:o,githubURL:r,footer:l,children:h}=e;const p=f();return(0,c.jsx)(c.Fragment,{children:(0,c.jsxs)(n(),{children:[(0,c.jsx)(s.A,{title:t,thumb:i,projectRoute:o,projectLink:a,githubURL:r}),(0,c.jsxs)(m.A,{gutter:0,children:[(0,c.jsx)(u.A,{xs:0,lg:5,children:(0,c.jsx)("div",{className:"project-toc-wrapper",children:(0,c.jsx)(d,{title:t})})}),(0,c.jsxs)(u.A,{xs:24,lg:19,children:[(0,c.jsx)("div",{className:"project-content-wrapper",style:{marginRight:p.lg?"17.5vw":"6vw",marginLeft:p.lg?0:"6vw"},children:h}),(0,c.jsx)("div",{className:"project-footer-wrapper",style:{display:"flex",justifyContent:"center",marginTop:"8vh",marginBottom:"5vh",marginRight:p.lg?"17.5vw":"6vw",marginLeft:p.lg?0:"6vw"},children:l?{footer:l}:"\u274b That's all! Thanks for reading. \u274b"})]})]})]})})}},6962:(e,t,i)=>{i.d(t,{Vq:()=>u});var a=i(27565),n=i(20477),s=function(){return s=Object.assign||function(e){for(var t,i=1,a=arguments.length;i<a;i++)for(var n in t=arguments[i])Object.prototype.hasOwnProperty.call(t,n)&&(e[n]=t[n]);return e},s.apply(this,arguments)};var o="",r=null,l=null,c=null;function h(){o="",null!==r&&r.disconnect(),null!==l&&(window.clearTimeout(l),l=null)}function d(e){return["BUTTON","INPUT","SELECT","TEXTAREA"].includes(e.tagName)&&!e.hasAttribute("disabled")||["A","AREA"].includes(e.tagName)&&e.hasAttribute("href")}function p(){var e=null;if("#"===o)e=document.body;else{var t=o.replace("#","");null===(e=document.getElementById(t))&&"#top"===o&&(e=document.body)}if(null!==e){c(e);var i=e.getAttribute("tabindex");return null!==i||d(e)||e.setAttribute("tabindex",-1),e.focus({preventScroll:!0}),null!==i||d(e)||(e.blur(),e.removeAttribute("tabindex")),h(),!0}return!1}function m(e){return a.forwardRef((function(t,i){var d="";"string"===typeof t.to&&t.to.includes("#")?d="#"+t.to.split("#").slice(1).join("#"):"object"===typeof t.to&&"string"===typeof t.to.hash&&(d=t.to.hash);var m={};e===n.k2&&(m.isActive=function(e,t){return e&&e.isExact&&t.hash===d});var u=function(e,t){var i={};for(var a in e)Object.prototype.hasOwnProperty.call(e,a)&&t.indexOf(a)<0&&(i[a]=e[a]);if(null!=e&&"function"===typeof Object.getOwnPropertySymbols){var n=0;for(a=Object.getOwnPropertySymbols(e);n<a.length;n++)t.indexOf(a[n])<0&&Object.prototype.propertyIsEnumerable.call(e,a[n])&&(i[a[n]]=e[a[n]])}return i}(t,["scroll","smooth","timeout","elementId"]);return a.createElement(e,s({},m,u,{onClick:function(e){var i;h(),o=t.elementId?"#"+t.elementId:d,t.onClick&&t.onClick(e),""===o||e.defaultPrevented||0!==e.button||t.target&&"_self"!==t.target||e.metaKey||e.altKey||e.ctrlKey||e.shiftKey||(c=t.scroll||function(e){return t.smooth?e.scrollIntoView({behavior:"smooth"}):e.scrollIntoView()},i=t.timeout,window.setTimeout((function(){!1===p()&&(null===r&&(r=new MutationObserver(p)),r.observe(document,{attributes:!0,childList:!0,subtree:!0}),l=window.setTimeout((function(){h()}),i||1e4))}),0))},ref:i}),t.children)}))}var u=m(n.N_);m(n.k2)},29780:()=>{}}]);
//# sourceMappingURL=69.4d724285.chunk.js.map