"use strict";(self.webpackChunkapp=self.webpackChunkapp||[]).push([[962],{22510:(e,t,i)=>{i.r(t),i.d(t,{default:()=>ge});i(27565);var n=i(50899),a=i(42779),r=i(46761),s=i(20791),o=i(39432),c=i(45577),l=i(79346),h=i(80651);const d=i.p+"static/media/tea_cerem_direct.c01e52a9c09c1eb13fe9.png",p=i.p+"static/media/tea_cerem_indirect.e97fe36c22df1ca25e87.png",m=i.p+"static/media/tea_cerem_specular.ee8a62527d4d757f1b3f.png",A=i.p+"static/media/tea_cerem_caustic.6faa5135080ef005ad2c.png",f=i.p+"static/media/tea_cerem_2048.11221379884f635f7a96.png",g=i.p+"static/media/csg_completed_brighter-crop.e82d1802c2da92303a57.png",u=i.p+"static/media/csg-breakdown.b6a5f2ae3f2de9a1628b.png",x=i.p+"static/media/t-value-operations.7807e0fb770db0d07ec0.png",b=i.p+"static/media/csg-fsm.946e6d049809dc03938b.png",y=i.p+"static/media/cone.38746363ec275d20fb90.png",j=i.p+"static/media/cylinder.18c994409b99c3dbbaa9.png",w=i.p+"static/media/ellipse.d93c8a4cc12ab0ebdb50.png",v=i.p+"static/media/hyperbolic-cylinder.527cf768e36b6325871d.png",$=i.p+"static/media/hyperbolic-paraboloid.38d735fa0690ed2b69b0.png",B=i.p+"static/media/hyperboloid-one-sheet.79fbe970e1582c1a9710.png",_=i.p+"static/media/hyperboloid-two-sheet.d6c35a40621d25576bb0.png",Q=i.p+"static/media/parabolic.8f25dfea522315dc0aa6.png",D=i.p+"static/media/face_normals.6a21c261944e1ff79bfb.png",I=i.p+"static/media/vertex_normals.8dca35807391e10e1788.png",T=i.p+"static/media/bv_overlay.74bfc584b8d0e2bb9c83.png",k=i.p+"static/media/lambertian_diffuse.6a9b187d1e95c75b0944.png",C=i.p+"static/media/phong.45d416570a046ff429db.png",R=i.p+"static/media/mirrors-1-bounce.8a084335369475a155e2.png",N=i.p+"static/media/mirrors-3-bounces.492aba58c530c91c2209.png",q=i.p+"static/media/mirrors-5-bounces.0d820de0699745543720.png",O=i.p+"static/media/mirrors-8-bounces.99cce737b0dac690d51a.png",z=i.p+"static/media/dielectric-no-fresnel-1.0f.9a341186557d19099082.png",H=i.p+"static/media/dielectric-no-fresnel-1.3f.17426a60f6e3276f12e3.png",E=i.p+"static/media/dielectric-no-fresnel-1.5f.885ef1663d2a25cdcc8c.png",L=i.p+"static/media/dielectric-no-fresnel-1.7f.73fecb2f8e29f98dcfd0.png",M=i.p+"static/media/dielectric-no-fresnel-2.5f.ea0ad815b99553f34ac2.png",F=i.p+"static/media/dielectric-fresnel-fresnel.3496ac2c6a2c39f7ea12.png",P=i.p+"static/media/dielectric-fresnel-schlick.f9d199fc9a0327a28371.png",U=i.p+"static/media/brighter-1-sample-crop.d5c3a473e848e965311e.png",S=i.p+"static/media/brighter-5-samples-crop.926be256e3a699ee62c6.png",G=i.p+"static/media/brighter-10-samples-crop.c99a3bb57baa25484907.png",W=i.p+"static/media/brighter-25-samples-crop.29f6697bee3d2c5fd827.png",V=i.p+"static/media/brighter-50-samples-crop.595b33fdbd51120d7778.png",Z=i.p+"static/media/brighter-100-samples-crop.92193104f3873beb6918.png",K=i.p+"static/media/brighter-200-samples-crop.c47a45d4829937f94849.png",X=i.p+"static/media/5xSSAA-crop.239ff7d535b82d3c002a.png",J=i.p+"static/media/10xSSAA-crop.e213c53c1590dbcae69c.png",Y=i.p+"static/media/25xSSAA-crop.10db6fa68bbeb9ef8d0e.png",ee=i.p+"static/media/50xSSAA-crop.2d11961282ecedc2dbd9.png",te=i.p+"static/media/cornell-wi.ff42ffb1d49579d3b62b.png",ie=i.p+"static/media/cornell-pm.c088335cbca40756b4ba.png",ne=i.p+"static/media/global_photon_map_visualisation.7755718c875993b2ddf8.png",ae=i.p+"static/media/caustic_photon_map_visualisation.ccc6dab67ec6d092bef5.png",re=i.p+"static/media/cornell-wi-512.bf6e06e3499e8db48062.png",se=i.p+"static/media/indirect_illum_1035313n.d2a4bcc5a64f886a9bc3.png",oe=i.p+"static/media/specular_glossy.6660754b0c3ac34b0f1a.png",ce=i.p+"static/media/caustics_filter_1024162.8dc08234b0d685c40ffb.png",le=i.p+"static/media/cornell-pm-512.bd2026d116a909b3dd58.png";i(73017);var he=i(8249),de=i(78277),pe=i(95569),me=i(92026),Ae=i(27929);const{useBreakpoint:fe}=n.Ay,ge=()=>{const e=fe();return(0,Ae.jsxs)(pe.A,{title:de.Meta.title,thumb:de.Meta.thumb,githubURL:"https://github.com/Skittss/RayTracer",children:[(0,Ae.jsx)("h1",{id:"overview",className:"raleway-title",children:"Overview"}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"1000px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:f,annotation:"Example render with global illumination"}),(0,Ae.jsx)(me.A,{preview:!1,src:d,annotation:"Stage 1: Direct illumination"}),(0,Ae.jsx)(me.A,{preview:!1,src:p,annotation:"Stage 2: Indirect illumination (diffuse)"}),(0,Ae.jsx)(me.A,{preview:!1,src:m,annotation:"Stage 3: Specular and Glossy"}),(0,Ae.jsx)(me.A,{preview:!1,src:A,annotation:"Stage 4: Indirect illumination (caustics)"})]}),(0,Ae.jsxs)("p",{children:["In this project, I delve into the powerful realm of ray tracing \u2014 a groundbreaking light transport technique that has reshaped the landscape of computer graphics. As technology advances, so does the demand for more realistic and immersive visual experiences in various applications such as gaming and animation. Ray tracing has emerged as a game-changer, enabling us to simulate the intricate behavior of light, resulting in visually stunning and physically accurate renders.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"This post is not entirely designed as a zero-knowledge read, and instead is probably best utilised as supplementary material when you have the basic concepts of 3D rendering and raytracing pinned down. I recommend two great reads if you don't feel comfortable jumping in here: ",(0,Ae.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://www.scratchapixel.com/index.html",children:"Scratchapixel"})," and ",(0,Ae.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://raytracing.github.io/books/RayTracingInOneWeekend.html",children:"Ray Tracing in One Weekend"})," which go into more detail than I do, albeit with a slightly different focus (no photon-mapping for example).",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Code snippets in this post are abbreviated for brevity. The full source code for this renderer is available on ",(0,Ae.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/Skittss/RayTracer",children:"GitHub"}),"."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"int-raycast",className:"raleway-title",children:"Rendering Objects by Casting Rays"}),(0,Ae.jsxs)("p",{children:["Consider a 3D scene. At its simplest, we have lights, objects, and a virtual camera. How do we generate an image of the objects, given the lights, from the viewpoint of the camera? In games and alike, perspective projection is used to map each object onto the image plane of the camera as the intrinsic properties of the camera are known, as well as the geometric information of all objects. This has the benefit of being fast to run, but in doing so we ommit detail. For example, it might not be immediately obvious how we produce shadows using projection. Or a bigger challenge - how would we render a mirror, or transparent objects such as glass? Rendering these phenomena is an inherit challenge with projection-based rendering, and thus sets the stage for raytracing. Raytracing is a light transport technique; it accurately simulates how light in the scene interacts with objects and eventually makes its way to a virtual camera, producing an image. The simulation of the light itself allows for physically accurate renders to be produced, contrary to projection-based rendering which employs auxilliary techniques to mimic physical phenomena.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Light travels in straight lines. This makes rays an appropriate data structure to keep track of how light travels throughout a scene. Rays are vectors in 3D space, defined by an origin point ",(0,Ae.jsx)(he.A,{children:"$O$"})," and direction ",(0,Ae.jsx)(he.A,{children:"$D$"}),". From this, we can identify every point that falls upon the ray with a line defined by a 'distance' parameter ",(0,Ae.jsx)(he.A,{children:"$t$"}),":",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$R=O+Dt$"})}),(0,Ae.jsx)("br",{}),"In other words, we can find any point along the line by starting at the origin of the ray, and traversing ",(0,Ae.jsx)(he.A,{children:"$t$"})," distance along the line in the direction of the ray.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"But how do we render objects using rays? The basic idea is to cast a ray for each pixel in your target image, and find where each ray intersects an object in the scene. We calculate the lighting and the intersection point, which determines the pixel colour. Repeating this process for each pixel gives us the final render. From this brief description, it should be apparent why raytracing on GPUs has been a recent topic of interest - the process is ",(0,Ae.jsx)("i",{children:"extremely"})," parallelisable, allowing GPU acceleration to push render times into realtime."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h1",{id:"core-concept",className:"raleway-title",children:"An Overview of Lighting Calculations"}),(0,Ae.jsxs)("p",{children:["How do we calculate lighting at intersection points? This process is variable depending on the specific raytracing technique used, but in general, we calculate a ",(0,Ae.jsx)("i",{children:"Bidirectional Reflectance Distribution Function"})," (BRDF) at each intersection. This function defines the characteristics of an objects material. At its most basic, this is colour, but may also incorporate other properties such as specular highlight approximations (e.g. in Phong materials). This function can be defined in any way you see fit, and may not necessarily be physically accurate.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The BRDF is defined as ",(0,Ae.jsx)(he.A,{children:"$f_r(\\textbf x, \\omega_i, \\omega_r)$"}),", a function of the intersection point ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," in local coordinate space of the object, incident light direction ",(0,Ae.jsx)(he.A,{children:"$\\omega_i$"}),", and reflected light direction ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"}),". Typically, ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"})," is simply ",(0,Ae.jsx)(he.A,{children:"$-D$"}),", i.e. the vector from the intersection point towards the camera, and ",(0,Ae.jsx)(he.A,{children:"$\\omega_i$"})," can be calculated by assuming light has come from a light in the scene, i.e. ",(0,Ae.jsx)(he.A,{children:"$\\textbf x - O_\\text{light}$"}),"."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"ray-shadow",className:"raleway-title",children:"Basic Shadows"}),(0,Ae.jsxs)("p",{children:["The BRDF alone does not paint the full picture of rendering as we still need a way of incorporating shadows. The simplest way of computing hard regions of shadow is to cast a secondary ray at the intersection point ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," towards lights, and only calculate the BRDF if the light is not occluded (i.e. there is no intersection between the ray and an object).",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"This simple approach works well for direct illumination (where we do not simulate light bouncing), but is not applicable to other parts of global illumination, which we will visit next. Further down the line we will additionally look at a method to render soft shadows, as this simple approach can only render strict shadow boundaries."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"global-illum",className:"raleway-title",children:"Global Illumination"}),(0,Ae.jsxs)("p",{children:["The main benefit of raytacing is that we can simulate many light bounces and BRDF interactions from each ray cast, aggregating them to produce a final colour. These light bounces might not come directly from a light therefore. This is called ",(0,Ae.jsx)("b",{children:"global illumination"}),". We consider light from all sources, including that which has been indirectly bounced around the scene. We need extra algorithms and data structures to support this kind of bouncing however, so at its simplest we can not allow bouncing, giving only ",(0,Ae.jsx)("b",{children:"direct illumination"}),"."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"rendering-eq",className:"raleway-title",children:"The Rendering Equation"}),(0,Ae.jsxs)("p",{children:["The rendering equation, introduced by James T. Kajiya, mathematically formalises the calculation of lighting, or 'reflected radiance'. I find it beneficial to keep this equation in mind, as it exactly defines what calculations we should do at each intersection and can make organising code a lot easier.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The rendering equation is defined as"]}),(0,Ae.jsx)("p",{children:(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$L_r(\\textbf{x}, \\omega_i, \\omega_r) =\n                        L_e + \\displaystyle\\int_\\Omega f_r(\\textbf{x}, \\omega_i, \\omega_r) L_i(\\textbf{x}, \\omega_i)(\\omega_i \\cdot \\textbf n)\\ d\\omega_i $"})})}),(0,Ae.jsxs)("p",{children:["where ",(0,Ae.jsx)(he.A,{children:"$L_r(\\textbf{x}, \\omega_i, \\omega_r)$"})," denotes the reflected radiance along a direction ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"})," at a point in the scene ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),". In other words, if ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"})," is the direction from ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," to a camera pixel, this is the amount of light we gather at that pixel, i.e. the rendered colour. ",(0,Ae.jsx)(he.A,{children:"$L_e$"})," denotes any light directly emitted from the object at ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),", and serves mostly to support rendering materials that emit light and other visible light sources (e.g. an area light).",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The integral component states that at point ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),", we gather all the incident radiance from all possible incident directions (",(0,Ae.jsx)(he.A,{children:"$\\omega_i$"}),") in a hemisphere above ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," (",(0,Ae.jsx)(he.A,{children:"$\\Omega$"}),"). We multiply each incident ray by the BRDF ",(0,Ae.jsx)(he.A,{children:"$f_r$"})," for its given direction to determine how much of the incident light is reflected along ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"})," - thus giving reflected radiance. We also apply Lambert's cosine law via ",(0,Ae.jsx)(he.A,{children:"$(\\omega_i \\cdot x)$"}),".",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The method by which this integral is approximated depends on the specific lighting implementation we are wishing to achieve. We are able to fit global illumination models and direct-illumination models (roughly) under this definition. For example, the basic direct-illumination ray tracing model can be described as approximating the integral by taking ",(0,Ae.jsx)(he.A,{children:"$\\Omega$"})," as the set of directions to visible lights from ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),". Monte Carlo Ray Tracing makes use of Monte Carlo techniques to approximate the integral with a large number of importance sampled ",(0,Ae.jsx)(he.A,{children:"$\\omega_i $"})," rays. And in similar fashion, photon mapping uses light bounce caching via the photon map to provide an estimate of ",(0,Ae.jsx)(he.A,{children:"$L_i$"})," for all directions ",(0,Ae.jsx)(he.A,{children:"$\\omega_i \\in \\Omega$"}),"."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"int-test",className:"raleway-title",children:"Geometry - Intersection Testing"}),(0,Ae.jsxs)("p",{children:["We now know that to render an individual pixel, we cast a ray for it, and determine which object in the scene it has hit. We then calculate lighting at that point, resulting in a colour for the pixel. In order to determine which object has been hit, we can begin by naively checking every object in the scene for intersection, and choose the one which was closest to the camera. It is worth noting that this is a particularly slow approach (especially when scenes have many objects), so we will consider acceleration structures to speed this process up later in this section.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The remainder of this section outlines how to calculate intersection points for a number of useful primitives: triangles (used in meshes), flat planes (and curved quadratic variants), spheres, and cuboids. The goal is to find the t-value for a given ray which intersects the primitive. We also need to calculate surface normals at intersection points in order to calculate lighting. Additionally, we will explore constructive solid geometry, which allows us to combine these basic primitives into more complex objects via boolean operations."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"int-plane",className:"raleway-title",children:"Planes"}),(0,Ae.jsxs)("p",{children:["We can determine if a ray intersects a given plane by noting that the vector from the plane center to any point on the plane will be perpendicular to the plane normal. i.e.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$(p - O_p)\\cdot n = 0$"})}),(0,Ae.jsx)("br",{}),"From this, we can determine if a ray intersects the plane by observing that if they indeed intersect, then there will be a common point between them, i.e. substitute ",(0,Ae.jsx)(he.A,{children:"$p$"})," for the ray equation:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$((O_r + Dt) - O_p)\\cdot n = 0$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\implies Dt\\cdot n + (O_r - O_p) \\cdot n = 0$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\implies t = \\displaystyle\\frac{(O_p - O_r)\\cdot n}{D \\cdot n} $"})}),(0,Ae.jsx)("br",{}),"Thus we have found the point of intersection (if it exists).",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"We are not quite done however. If we were only to calculate this t-value with no other considerations, we would not be able to give the plane specific dimensions (width and height). As it stands, any the plane will have infinite width and height. We can add width and height into the intersection calculation by considering an alternative vector definition of a 3D plane:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$p=O_p + u\\lambda + v\\mu$"})}),(0,Ae.jsx)("br",{}),"By ensuring that ",(0,Ae.jsx)(he.A,{children:"$\\lambda$"})," and ",(0,Ae.jsx)(he.A,{children:"$\\mu$"})," are perpendicular along the plane (i.e. they form an orthonormal basis with the plane normal), we can easily cull intersections which fall outside a certain distance in each direction. This allows us to give the plane a width and height, instead of it being infinite. It is easy to calculate this orthonormal basis: We provide an up vector (normal) and right vector (tangent) and can calculate the bitangent by taking the cross product of them.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"An implementation of this intersection calculation is shown in the code snippet below."]}),(0,Ae.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,Ae.jsx)(l.A,{language:"cpp",showLineNumbers:!0,style:h.A,startingLineNumber:0,children:"\nvector<Hit> Plane::intersection(Ray ray) {\n    \n    vector<Hit> hits;\n\n    Vector ro = ray.position - center;\n    float dot_product = ro.dot(normal);\n    if (dot_product == 0) return hits;\n    if (dot_product < 0 && !twoside) return hits;\n\n    float denominator = ray.direction.dot(normal);\n    if (fabs(denominator) < 0.0001f) return hits;\n\n    float t = -dot_product / denominator; // Unbounded hit on surface plane t\n\n    // Calculate against 3D Plane equation: c + u x d1 + v x d2\n    Vector hit_pos = ray.position + t * ray.direction;\n\n    Vector center_offset = Vector::v_abs(hit_pos - center);\n    float ortho_1 = fabs(tangent.dot(center_offset));\n    float ortho_2 = fabs(bitangent.dot(center_offset));\n\n    if (ortho_1 < tangent_size && ortho_2 < bitangent_size) {        \n        // [Abbreviated] ...Emplace new Hit(t) obj to back of hits\n    }\n\n    return hits;\n}"})}),(0,Ae.jsx)("p",{children:"Finally, the surface normal at an intersection point is constant, and provided with the definition of the plane."}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"int-triangle",className:"raleway-title",children:"Triangles"}),(0,Ae.jsxs)("p",{children:["Triangles are perhaps the most important primitive to be able to render. By rendering triangles, we can render arbitrary triangle meshes which are ubiquitous in computer graphics. Throughout this post, this can be seen with the Utah Teapot - all renders of it were made using a triangle mesh loaded from a .obj file.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Triangle intersection is well explored and well optimised. In this implementation the standard 'Moller Trumbore' algorithm is used to calculate the intersection. The core idea behind this algorithm is to use Barycentric Coordinates to calculate a potential intersection point. Barycentric coordinates express points as a linear combination of vertex positions. in this case, we define a potential intersection point as a linear combination of the triangles 3 vertices:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$p=(1-u-v)v_1 + uv_2 + vv_3$"})}),(0,Ae.jsx)("br",{}),"A valid intersection point is one with valid with valid coefficients for ",(0,Ae.jsx)(he.A,{children:"$v_1, v_2, v_3$"}),", i.e. ",(0,Ae.jsx)(he.A,{children:"$u + v = 1$"}),". The algorithm calculates these coefficients for the potential intersection point, and rejects any intersections where the above property does not hold.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"A C++ implementation is shown below."]}),(0,Ae.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,Ae.jsx)(l.A,{language:"cpp",showLineNumbers:!0,style:h.A,startingLineNumber:0,children:"\nbool UTIL::moller_trumbore(\n\tconst Ray& ray, \n\tconst Vector &v0, const Vector &v1, const Vector &v2, \n\tfloat &t, float &u, float &v\n) {\n\t\n\tconst float epsilon = 0.00001f;\n\tVector edge1, edge2, h, s, q;\n\tfloat a, f;\n\n\tedge1 = v1 - v0;\n\tedge2 = v2 - v0;\n\n\th = Vector::cross_product(ray.direction, edge2);\n\ta = Vector::dot_product(edge1, h);\n\n\tif (a > -epsilon && a < epsilon) return false;\n\n\tf = 1.0f/a;\n\ts = ray.position - v0;\n\tu = f * Vector::dot_product(s, h);\n\n\tif (u < 0.0f || u > 1.0f) return false; // Ensure valid barycentric coordinates (i.e. not outside triangle).\n\n\tq = Vector::cross_product(s, edge1);\n\tv = f * Vector::dot_product(ray.direction, q);\n\n\tif (v < 0.0f || u + v > 1.0f) return false; // Barycentric coord check again.\n\n\tt = f * Vector::dot_product(edge2, q);\n\n\tif (t > epsilon) return true;\n\treturn false; // Ignore intersections behind the ray origin.\n}"})}),(0,Ae.jsxs)("p",{children:["The surface normal for a triangle is a constant, and can be calculated via the cross product like in a plane. However, usually we load these normals from a file when dealing with triangular meshes. This makes our job easier, but we also must consider the implication of using a single normal for an entire triangle.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"In a large mesh, triangles are usually an approximation of the true geometric form we wish to capture. If we could easily and efficiently render arbitrary continuous surfaces, we would. When using a single surface normal for a whole triangle, this approximation becomes more apparent. For smooth surfaces, it would be beneficial if we could change the surface normal of a triangle depending on where it is hit. Thus we could mimic smoother lighting on a low-poly surface without giving up lots of performance by using many more triangles.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Per-vertex normals solve this problem. Using the barycentric coordinates generated from the moller-trumbore algorithm (",(0,Ae.jsx)(he.A,{children:"$u$"})," and ",(0,Ae.jsx)(he.A,{children:"$v$"}),"), we can interpolate between vertex normals, giving a smooth looking surface with only a few triangles. Vertex normals may be provided within the mesh file, but they can also be computed manually by averaging the face normals of neighbouring faces otherwise. In a triangle mesh, we consider three adjacent faces for each triangle."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:3e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"512px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:D,annotation:"Triangular mesh rendered with face normals."}),(0,Ae.jsx)(me.A,{preview:!1,src:I,annotation:"Triangular mesh rendered with vertex normals and interpolation."})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"int-sphere",className:"raleway-title",children:"Spheres"}),(0,Ae.jsxs)("p",{children:["Calculating the intersection of a sphere is simple, and is derrived from its cartesian definition:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$x^2+y^2+z^2=R^2$"})}),(0,Ae.jsx)("br",{}),"Thus we can implicitly define a point on the surface of the sphere as",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$p^2-R^2=0$"})}),(0,Ae.jsx)("br",{}),"Similarly to the intersection for a plane; if there is an intersection, there will be a common point between the sphere and the ray equation. Therefore substituting ",(0,Ae.jsx)(he.A,{children:"$p=O + Dt$"}),":",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$(O + Dt)^2-R^2=0$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\implies D^2t^2 + 2ODt + O^2 - R^2=0$"})}),(0,Ae.jsx)("br",{}),"gives a quadratic equation for ",(0,Ae.jsx)(he.A,{children:"$t$"})," which can be solved via the general quadratic formula where ",(0,Ae.jsx)(he.A,{children:"$a=D^2,\\ b=2OD,\\ c=O^2-R^2$"}),".",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"This intersection calculation, with variable center point for the sphere ",(0,Ae.jsx)(he.A,{children:"$O_s$"})," is implemented as below."]}),(0,Ae.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,Ae.jsx)(l.A,{language:"cpp",showLineNumbers:!0,style:h.A,startingLineNumber:0,children:"\nvector<Hit> Sphere::intersection(Ray ray)\n{\n\tvector<Hit> hits;\n\n\t// Note: simplification of quadratic formula by assuming b = some 2n.\n\tVector ray_origin_to_center = ray.position - center;\n\tfloat a = ray.direction.length_squared();\n\tfloat b_over_two = ray_origin_to_center.dot(ray.direction);\n\tfloat c = ray_origin_to_center.length_squared() - radius * radius;\n\tfloat discriminant = b_over_two * b_over_two - a * c;\n\n\tif (discriminant < 0.0f) return hits; // No intersection if discrim < 0\n\n\tfloat sqrt_d = sqrtf(discriminant);\n\n\t// Check smallest root first\n\tfloat t = (-b_over_two - sqrt_d) / a;\n    // [Abbreviated] ...Emplace new Hit(t) obj to back of hits\n\n    // Check larger root\n\tt =  (-b_over_two + sqrt_d) / a;\n    // [Abbreviated] ...Emplace new Hit(t) obj to back of hits\n\n    return hits;\n}"})}),(0,Ae.jsx)("p",{children:"Additionally, we need the surface normal on the sphere at the point of intersection. This is simply the vector from the sphere center to the intersection point, normalised:"}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\textbf n = (p - O_s) / R$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"int-cuboid",className:"raleway-title",children:"Cuboids"}),(0,Ae.jsxs)("p",{children:["To implement cuboid intersection, the ",(0,Ae.jsx)("i",{children:"Axis-aligned bounding box"})," (AABB) algorithm can be used. By default, the algorithm works on a box centered at the origin and aligned with the 3 primary axes, but we are able to position it anywhere in 3D space by defining a local coordinate system. We define a local position a local orthonormal basis (set of axes) aligned with the edges of the cuboid. We then convert the ray position and direction into this local coordinate space before doing the AABB calculation. In this local coordinate space, the cuboid is centered at the origin and aligned with the primary axes, so AABB can now be used.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The idea behind the AABB intersection algorithm is that we can easily define 6 straight lines with the minimum and maximum extents of each primary axis, which in turn correspond with each edge of the cuboid. E.g. ",(0,Ae.jsx)(he.A,{children:"$x=\\min_x, y=\\min_y, z=\\min_z$"})," and similarly for the maximum bounds. We can perform a simple substitution with the ray equation in the targetted axis to calculate the t-value for each one, for example in ",(0,Ae.jsx)(he.A,{children:"$x$"}),":",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$O_x+D_xt=\\min_x$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\implies O_x+D_xt=\\displaystyle\\frac{\\min_x - O_x}{D_x}$"})}),(0,Ae.jsx)("br",{}),"Finally, we check if the t-value of each intersection falls within the bounds of the cuboid (as the lines extend in each axis indefinitely), and note that in order to have a valid box intersection, we need valid intersection pair from different primary axes. In other words, we have an intersection only when the ray enters the cuboid from one face, and exits through another.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"An optimised implementation of the above is shown below."]}),(0,Ae.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,Ae.jsx)(l.A,{language:"cpp",showLineNumbers:!0,style:h.A,startingLineNumber:0,children:"\nvector<Hit> Cuboid::intersection(Ray ray) {\n    \n    vector<Hit> hits;\n\n    Vector local_ray_position = UTIL::world_to_local(ray.position, tangent, up, bitangent);\n    Vector local_ray_dir = UTIL::world_to_local(ray.direction, tangent, up, bitangent);\n\n    Vector half_bounds = Vector(width_ta, width_n, width_bt);\n    Vector min_bound = pos - half_bounds;\n    Vector max_bound = pos + half_bounds;\n    Vector inv_dir = 1.0f / local_ray_dir;\n\n    Vector negatives = Vector(\n        inv_dir.x < 0,\n        inv_dir.y < 0,\n        inv_dir.z < 0\n    );\n\n    Vector t_min = inv_dir * (Vector::v_lerp(max_bound, min_bound, negatives) - local_ray_position);\n    Vector t_max = inv_dir * (Vector::v_lerp(min_bound, max_bound, negatives) - local_ray_position);\n\n    // Check x-y corner miss edge cases\n    if (t_min.x > t_max.y || t_min.y > t_max.x) return hits;\n\n    float t_near = t_min.x;\n    float t_far  = t_max.x;\n    Vector min_normal = Vector(-1.0f, 0.0f, 0.0f);\n    Vector max_normal = Vector(1.0f, 0.0f, 0.0f);\n    \n    if (t_min.y > t_min.x) {t_near = t_min.y; min_normal = Vector(0.0f, 1.0f, 0.0f);} // Note +ve y is downwards in this renderer's convention\n    if (t_max.y < t_max.x) {t_far  = t_max.y; max_normal = Vector(0.0f, -1.0f, 0.0f);}\n\n    // Check x (or y, whichever is the relevant intersection) - z miss edge cases\n    if (t_near > t_max.z || t_min.z > t_far) return hits;\n    \n    if (t_min.z > t_near) {t_near = t_min.z; min_normal = Vector(0.0f, 0.0f, -1.0f);}\n    if (t_max.z < t_far)  {t_far  = t_max.z; max_normal = Vector(0.0f, 0.0f, 1.0f);}\n\n    // Note there should *always* be two hits to a cuboid in regular euclidian space.\n    // [Abbreviated] ...Emplace new Hit(t_near) obj to back of hits\n    // [Abbreviated] ...Emplace new Hit(t_far) obj to back of hits\n\n    return hits;\n}"})}),(0,Ae.jsxs)("p",{children:["To get the surface normal of an intersection in AABB, we can simply index from a predefined table depending on the position of the intersection point (i.e. which minimum bound it lays on). In local coordinate space, there are 6 fixed surface normals:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:[(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}1\\\\ 0 \\\\ 0\\end{pmatrix},$"}),(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}-1\\\\ 0 \\\\ 0\\end{pmatrix},$"}),(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}0\\\\ 1 \\\\ 0\\end{pmatrix},$"}),(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}0\\\\ -1 \\\\ 0\\end{pmatrix},$"}),(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}0\\\\ 0 \\\\ 1\\end{pmatrix},$"}),(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix}0\\\\ 0 \\\\ -1\\end{pmatrix}$"})]}),(0,Ae.jsx)("br",{}),"which are then transformed into global coordinate space by performing the inverse of the global to local coordinate calculation performed earlier."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"int-quadratic",className:"raleway-title",children:"Quadratic Surfaces"}),(0,Ae.jsxs)("p",{children:["Quadratic surfaces are characterised by second degree polynomials. They are very similar to ubiquitous second-degree polynomials in ",(0,Ae.jsx)(he.A,{children:"$\\R^2$"})," which are undoubtedly familiar: ",(0,Ae.jsx)(he.A,{children:"$y=x^2$"})," (parabola), ",(0,Ae.jsx)(he.A,{children:"$x^2 + y^2 = r$"})," (circle), etc. It would be more appropriate to call these unique cases (formally, normal forms) of the general quadratic equation. Quadratic surfaces are the same concept but applied to ",(0,Ae.jsx)(he.A,{children:"$\\R^3$"})," defined by the following:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$Ax^2 + By^2 + Cz^2 + Dxy + Eyz + Fxz + Gx + Hy + Iz + J = 0$"})}),(0,Ae.jsx)("br",{}),"The ray-intersection calculation is handled no differently than for any other implicit surface, and the specific t-values can be calculated using the quadratic equation after performing the substitution ",(0,Ae.jsx)(he.A,{children:"$\\begin{pmatrix} x & y & z\\end{pmatrix} = O + Dt$"}),"  on the above equation where ",(0,Ae.jsx)(he.A,{children:"$O$"})," and ",(0,Ae.jsx)(he.A,{children:"$D$"})," are the ray origin and direction respectively. This results in a system of equations for t which can be solved via matrix calculations.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The only remaining task is calculating the surface normals, which is again no different than for any other continuous implicit surface; the partial derivative of the quadratic surface equation in ",(0,Ae.jsx)(he.A,{children:"$x$"}),", ",(0,Ae.jsx)(he.A,{children:"$y$"})," and ",(0,Ae.jsx)(he.A,{children:"$z$"}),". Below are the different normal form quadratic surfaces capable of being created via the above equation.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:3e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{src:w,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Ellipse ",(0,Ae.jsx)(he.A,{children:"$(C=0.5)$"})]})}),(0,Ae.jsx)(me.A,{src:y,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Cone ",(0,Ae.jsx)(he.A,{children:"$(B=-1,\\ J=0)$"})]})}),(0,Ae.jsx)(me.A,{src:j,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Cylinder ",(0,Ae.jsx)(he.A,{children:"$(B=0)$"})]})}),(0,Ae.jsx)(me.A,{src:Q,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Paraboloid ",(0,Ae.jsx)(he.A,{children:"$(B,J=0,\\ H=-1)$"})]})}),(0,Ae.jsx)(me.A,{src:B,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Hyperboloid of 1 sheet ",(0,Ae.jsx)(he.A,{children:"$(B=-1)$"})]})}),(0,Ae.jsx)(me.A,{src:_,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Hyperboloid of 2 sheets ",(0,Ae.jsx)(he.A,{children:"$(B=-1,\\ J=1)$"})]})}),(0,Ae.jsx)(me.A,{src:v,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Hyperbolic Cylinder ",(0,Ae.jsx)(he.A,{children:"$(B=0,\\ C=-1)$"})]})}),(0,Ae.jsx)(me.A,{src:$,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Hyperbolic Paraboloid ",(0,Ae.jsx)(he.A,{children:"$(B,J=0,\\ C,H=-1)$"})]})})]}),(0,Ae.jsx)("br",{}),"In order to visualise these quadratic surfaces properly, an axis-aligned bounding box (AABB) is used to bound any intersection points (i.e. they must be inside the AABB to be valid hits) so that they do not display indefinitely into the distance."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"csg",className:"raleway-title",children:"Constructive Solid Geometry"}),(0,Ae.jsxs)(s.A,{gutter:[16,0],style:{margin:"0 auto",width:"100%",maxWidth:"1000px"},children:[(0,Ae.jsx)(o.A,{span:e.sm?12:24,children:(0,Ae.jsx)(c.A,{src:g})}),(0,Ae.jsx)(o.A,{span:e.sm?12:24,children:(0,Ae.jsx)(c.A,{src:u})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)("p",{children:["Constructive solid geometry is a technique which allows solids to be combined via boolean operations, allowing more complex geometry to be constructed from basic primitives. The basic three operations we will be working with here are union, intersection, and difference. For example, we could create a disc via calculating the intersection of a sphere and a cuboid.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Constructive solid geometry is implemented as the post-order traversal of a binary tree of 3D objects under elementary set operations. We organise objects in a tree as we want to be able to calculate boolean operations between multiple objects, not just between a pair. Post order traversal ensures the lowest-level intersections are calculated first and allows them be combined via set operations as the traversal moves up the tree. Nodes of the CSG tree are created by providing pairs of other CSG nodes or just basic 3D objects. The tricky part of implementing CSG comes down to calculating the intersection, union, and difference of two sets of ray-intersections (hits). Luckily, this problem can be visualised and reduced to calculating these operations on two 1D number lines:"]}),(0,Ae.jsx)("div",{style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:(0,Ae.jsx)(me.A,{src:x})}),(0,Ae.jsxs)("p",{children:["Calculating the union is rather straight forward. The problem can be thought of the same as matching parentheses. The two sets of hits are merged into one and a depth ",(0,Ae.jsx)(he.A,{children:"$d$"})," is defined. The merged set of hits is iterated over, with ",(0,Ae.jsx)(he.A,{children:"$d$"})," denoting how many objects we are in at each iteration. ",(0,Ae.jsx)(he.A,{children:"$d$"})," is initialised at 0, 1, or 2 depending on if the first hits for the two objects were entering or exiting hits. Upon entering an object, ",(0,Ae.jsx)(he.A,{children:"$d$"})," is incremented, and upon exiting an object, ",(0,Ae.jsx)(he.A,{children:"$d$"})," is decremented. Under this algorithm, the set of union points is just the set of points at which ",(0,Ae.jsx)(he.A,{children:"$d=0$"})," before entering, or ",(0,Ae.jsx)(he.A,{children:"$d=0$"})," after exiting.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Calculating the difference and intersection is slightly more complicated, but they both follow a similar approach. Again, the sets of hits are merged into one, and are iterated over. Instead of keeping track of a depth value, the booleans ",(0,Ae.jsx)(he.A,{children:"$L_\\text{prev},L_\\text{curr}$"})," and ",(0,Ae.jsx)(he.A,{children:"$R_\\text{prev},R_\\text{curr}$"})," are defined which denote if we were in object ",(0,Ae.jsx)(he.A,{children:"$L$"})," or ",(0,Ae.jsx)(he.A,{children:"$R$"})," after the last hit, and if we are in them after the current hit that is being iterated over. This is easy to keep track of by checking if a hit is entering or exiting at each iteration. For the hit that is currently being iterated over, the equation below can be evaluated to check for intersection",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$I=((R_\\text{prev}\\ne R_\\text{curr})\\land (L_\\text{prev}\\lor L_\\text{curr}))\\lor((L_\\text{prev}\\ne L_\\text{curr})\\land(R_\\text{prev}\\lor R_\\text{curr}))$"})}),(0,Ae.jsx)("br",{}),"and the following for difference",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$I=((L_\\text{prev}\\ne L_\\text{curr})\\land (\\lnot R_\\text{prev}\\land \\lnot R_\\text{curr}))\\lor((R_\\text{prev}\\ne R_\\text{curr})\\land(L_\\text{prev}\\lor L_\\text{curr}))$"})}),(0,Ae.jsx)("br",{}),"The intuition for these equations can be thought of as a finite state machine, shown below. Intersection hits are the edges to and from state '",(0,Ae.jsx)(he.A,{children:"$L\\land R$"}),"', and difference hits are the edges to and from '",(0,Ae.jsx)(he.A,{children:"$L$"}),"'. It is worth noting that union could also be calculated in a similar fashion, however the depth approach above is more succinct."]}),(0,Ae.jsx)("div",{style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:(0,Ae.jsx)(me.A,{src:b})}),(0,Ae.jsxs)("p",{children:["The only real technical consideration remaining is that the normals of any hits selected from object ",(0,Ae.jsx)(he.A,{children:"$R$"})," during a difference operation must be negated as they create a negative surface imprint."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"acceleration",className:"raleway-title",children:"Acceleration Structures"}),(0,Ae.jsxs)("p",{children:["Rendering certain objects can become very costly when done naively. The main perpetrators in this implementation are mesh objects (i.e. the teapot) and CSG trees. The high cost can be attributed to their expensive intersection calculation. Without any acceleration structure, this intersection must be fully checked for every pixel in the rendered image. For a mesh, this may be thousands to hundreds of thousands of triangle intersections, per pixel in the image. This is extremely wasteful - for example if a mesh is visible for only a few pixels in the image, an overwhelming majority of intersections will be false yet we do full work for every pixel in the image",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Bounding objects are acceleration structures which cut the number of intersection calculations we have to do considerably. This is achieved by first coarsely defining the bounds of an object via a cheaper intersection algorithm, and only then doing an expensive intersection calculation when the coarse intersection evaluates to true."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"aabb",className:"raleway-title",children:"Bounding Primitives"}),(0,Ae.jsx)("p",{children:"A simple approach is to simply bound complex objects by a primitive volume, reusing the intersection code for that specific primitive. A common approach is to use a AABB (cuboid) as the calculation to fit the box to another object is simple - we simply make an AABB at the same position as the complex object, and with its width and height to the maximum and minimum object bounds. This will speed up intersection calculations considerably. We begin by doing a check against the primitive bounding volume, allowing us to cull any intersection calculations where it is obvious that there will never be an intersection. This notably increases performance when rendering triangular meshes, as the number of triangle intersection checks can be extremely large for each raycast."}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"bv",className:"raleway-title",children:"14-Plane Bounding Volumes"}),(0,Ae.jsx)("p",{children:"Performance is still left on the table with AABB and primitives however. Bounding primitives usually only loosely fit to the underlying object, meaning there are still many cases where we will end up doing a full intersection check when there should clearly be no intersections. Kay and Kajiya introduced a method for bounding volume calculations defined by 14 planes which closer approximates more complex geometry while still being cheap. This closer approximation allows for an even larger number of costly intersection calls to be culled. The planes defined for the volume are in pairs, similar in essence to opposite faces of an AABB, and in fact the first 6 planes are exactly that. The remaining 8 planes are pairs along each diagonal of the 3 primary axes. The intersection calculation is relatively simple. Intersection points for each plane-pair are calculated. If the closest intersection has a larger t-value than the furthest intersection (i.e. the ray is facing away from the pair of planes), then there must be no intersection. If this is not the case for all plane-pairs, there is a valid intersection."}),(0,Ae.jsx)("div",{style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"1500px"},children:(0,Ae.jsx)(me.A,{src:T,annotation:"14-plane bounding volume applied to a mesh of the Utah Teapot, visualised "})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"bvh",className:"raleway-title",children:"Bounding Volume Hierarchies (BVH)"}),(0,Ae.jsxs)("p",{children:["Bounding Volume Hierarchies allow us to further cull intersection calculations by arranging objects in our scene in a hierarchy. This is typically done using a tree data structure; we can use a binary tree, or a wider tree (i.e. variable number of nodes) to group similar objects better. We create new bounding volumes (nodes) for groups of objects in our scene, allowing us to first quickly check this parent node for intersection and cull depending on the result. We know if a ray does not intersect a parent volume, it can't intersect any children.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Though not implemented in this raytracer (as we work with typically a small number of objects), it is fairly easy to implement a simple BVH. Even a simple scene will be useful when dealing with scenes that are composed of many triangle-dense meshes for example."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"materials",className:"raleway-title",children:"Materials"}),(0,Ae.jsxs)("p",{children:["Materials determine what colour an object is rendered with, using the lighting they are under. Materials are simply implementations of a BRDF calculation to calculate reflected radiance (loosely speaking, the colour we see). At a technical level, we need one procedure for doing the BRDF calculation, and another for sampling the incident radiance which is used in the calculation. This is because different different materials interact with light in different ways, and is a particular concern with ",(0,Ae.jsx)("i",{children:"global materials"}),", ones which sample radiance from from different locations than just the intersection point (think reflection and refraction). We will encounter examples of these materials later.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Before we begin, some terminology. Albedo ",(0,Ae.jsx)(he.A,{children:"$(\\rho)$"})," refers to the intrinsic colour of an object. It specifically defines the distribution of reflected light from an object (i.e. what proportion of RGB bands are reflected), but can be thought of simply as 'base colour'. We may choose to define more than one albedo for an object which describes the colour of reflected light under different circumstances. A good example of this is the Phong lighting model, in which we define 3 separate albedos for ambient, diffuse, and specular lighting."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"diffuse",className:"raleway-title",children:"Lambertian Diffuse"}),(0,Ae.jsxs)("p",{children:["Lambertian Diffuse is a simple material that only incorporates diffuse lighting onto the target object. Diffuse lighting refers to soft and gradual shadows which arise on matte materials from the random scattering of light at an object's surface. When light hits the surface, it can be thought of being randomly scattered in a hemisphere above the intersection location (this is a simplification - in reality there is some level of ",(0,Ae.jsx)("i",{children:"subsurface scattering"}),"). The intensity of reflected light obeys Lambert's cosine law, in other words, it is less intense at oblique viewing angles. This can be characterised by the following BRDF:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$f_r(\\textbf x, \\omega_i, \\omega_r)=\\displaystyle\\frac{\\rho_d}{\\pi}$"})}),(0,Ae.jsx)("br",{}),"noting that lambert's cosine term ",(0,Ae.jsx)(he.A,{children:"$(\\omega_i\\cdot \\textbf n)$"})," is included in the full rendering equation."]}),(0,Ae.jsx)("div",{style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:(0,Ae.jsx)(me.A,{src:k,annotation:"Cube rendered with a lambertian diffuse material."})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"phong",className:"raleway-title",children:"Phong Lighting Model"}),(0,Ae.jsxs)("p",{children:["The Phong lighting model incorporates ambient, diffuse, and specular approximations into the lighting calclation. Diffuse lighting we have seen already with Lambertian Diffuse, but what are ambient and specular lighting? Ambient lighting refers to the ",(0,Ae.jsx)("i",{children:"ambient light"})," in a scene, under which all objects are influenced even without making specific lights objects to emit the light. This is simply a constant light colour which all objects should be affected by. Specular lighting are intense reflections of light caused by light directly reflecting into the camera. We see this is glossy objects, mirrors, and alike. Some proper specular materials are introduced later (Mirrors, dielectrics), but we can make some simple approximations of specular lighting and incorporate them into the BRDF calculation.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$f_r(\\textbf x, \\omega_i, \\omega_r)=L_\\text{ambient} + L_\\text{diffuse} + L_\\text{specular}$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$L_\\text{ambient} = \\rho_a$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$L_\\text{diffuse} = \\displaystyle\\frac{\\rho_d}{\\pi}$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$L_\\text{specular} = \\rho_s\\cdot(\\omega_r\\cdot\\text{reflect}(\\omega_i, \\textbf n))^\\alpha$"})}),(0,Ae.jsx)("br",{}),"Ambient lighting is a constant ",(0,Ae.jsx)(he.A,{children:"$\\rho_a$"}),", and we reuse diffuse lighting calculations from lambertian diffuse, so the main addition here is the specular term. We incorporate a specular albedo for colour control, and calculate a similarity measure via cross product between the reflected radiance direction (usually the camera ray direction, inverted), and the perfect mirror-like reflection of light from the direction of incident radiance. What we are doing here is adding specular colour proportionally to how much light perfectly reflects into the camera, thus giving us specular highlights. ",(0,Ae.jsx)(he.A,{children:"$\\alpha$"})," is included for highlight attenuation. Since ",(0,Ae.jsx)(he.A,{children:"$\\omega_r\\cdot\\text{reflect}(\\omega_i, \\textbf n)\\in[0, 1]$"}),", exponentinentiation to ",(0,Ae.jsx)(he.A,{children:"$\\alpha$"})," means values further from 1 will contribute less; exponential light falloff for the highlights. Thus, a higher value for ",(0,Ae.jsx)(he.A,{children:"$\\alpha$"})," leads to sharper specular highlights. A typical value is ",(0,Ae.jsx)(he.A,{children:"$\\alpha\\approx 20$"}),"."]}),(0,Ae.jsx)("div",{style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"512px"},children:(0,Ae.jsx)(me.A,{src:C,annotation:"Utah Teapot and a sphere rendered with a Phong material."})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"textures",className:"raleway-title",children:"Basic Textures"}),(0,Ae.jsxs)("p",{children:["So far, the albedos of our materials have been constant. This limits us only to block colours for our objects. Textures are images which we can map colour from onto objects, and are a big factor in making realistic, or artistically styled renders. The way colour information is mapped from texture to object is a ",(0,Ae.jsx)("i",{children:"UV map"}),". We define UV coordinates for all of our geometry, which specifies what pixel we should look at in a texture image for the object's colour.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"We have already implicitly seen a few ways of generating UV coordinates: In planes they were simply direction coefficients from the cartesian definition of plane-points, and for triangles they were given by the barycentric coordinates. In a triangular mesh, they are given per-vertex, and we interpolate texture colour across triangular faces.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"There are different ways to generate UV coordinates for a number of objects (e.g. spheres), but I will not delve into them all here. The rest of the implementation is easy once we generate UV coordinates, we simply replace ",(0,Ae.jsx)(he.A,{children:"$\\rho$"})," in calculations with a uv-read from a texture. This can be an image file, or even procedurally generated, such as the checkerboard pattern seen throughout this post."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"mirrors",className:"raleway-title",children:"Mirrors"}),(0,Ae.jsxs)("p",{children:["Perfect mirrors assume that all incident light is perfectly reflected about their surface normal according to the law of reflection: ",(0,Ae.jsx)(he.A,{children:"$\\theta_i = \\theta_r$"}),". This gives rise to the below equation via basic geometry, which can be used to calculate the reflection of an incident direction about a normal ",(0,Ae.jsx)(he.A,{children:"$\\textbf n$"}),".",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\omega_r = \\omega_i - 2(\\omega_i \\cdot \\textbf n)\\textbf n$"})}),(0,Ae.jsx)("br",{}),"It should be noted that directional vectors are always normalised. (otherwise some very strange and difficult to debug results can occur!)",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Now that the reflection direction about a normal can be calculated, rendering a perfect mirror material is a fairly simple process; a primary ray is cast from the camera, and upon hitting a perfect mirror at ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),", a secondary ray is generated at ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," with direction calculated via ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"}),". This is done recursively until a non-specular surface is hit. Radiance is still accumulated at specular hits of the recursive ray cast, allowing for tinted mirrors.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"A final consideration is one for avoiding infinite loops. The above process will infinitely loop in the case where an infinite mirror setup is created (two mirrors facing one another with opposite normals, and a ray fired along one of these normals). To avoid this, a maximum recursion depth must be defined to terminate the recursion after a certain amount of bounces. Luckily, this doesn\u2019t majorly affect the rendered image for most scenes, and still 5 to 8 bounces is enough to get a very realistic looking reflection even with multiple participating mirror surfaces.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:2e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:R,annotation:"Mirrors with 1 bounce calculated"}),(0,Ae.jsx)(me.A,{preview:!1,src:N,annotation:"Mirrors with 3 bounces calculated"}),(0,Ae.jsx)(me.A,{preview:!1,src:q,annotation:"Mirrors with 5 bounces calculated"}),(0,Ae.jsx)(me.A,{preview:!1,src:O,annotation:"Mirrors with 8 bounces calculated"})]}),"The implementation of mirrors outlined is a basic one - more complex mirrors such as 'fuzzy mirrors' can also be implemented by changing the BRDF. With fuzzy mirrors for example, instead of deterministically calculating the reflected ray ",(0,Ae.jsx)(he.A,{children:"$\\omega_r$"}),", we can sample from a cone centered about the perfect reflection angle. This way, we mimick the scattering of light rays on an imperfect reflective surface. A simple way of implementing this is to choose a random position on a sphere centered about a point on the true reflected ray. A higher radius sphere means more fuzz."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"dielectrics",className:"raleway-title",children:"Dielectrics"}),(0,Ae.jsx)("p",{children:"Dielectrics are materials which can additionally refract incident light through them causing radiance to be transmitted through the object. A common example is glass. Refraction is handled the same as reflection in that secondary specular rays are generated, however their direction is calculated according the below equation, derived from Snell's law."}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\omega_r = r\\omega_i + \\textbf n \\bigg(rc- \\sqrt{1 - r^2(1 - c^2)}\\bigg) \\ \\ \\ \\text{where } c=-\\textbf n \\cdot \\omega_i, \\ \\text{and } {r=\\displaystyle\\frac{\\eta_1}{\\eta_2}}$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)("p",{children:["A few technical considerations here are that when light exits a medium, the normal of the medium should be flipped if necessary to face the incident specular ray (i.e. ",(0,Ae.jsx)(he.A,{children:"$\\omega_i\\cdot \\textbf n \\lt 0$"}),") as Equation 3 only deals light incident to the normal. In a similar manner, ",(0,Ae.jsx)(he.A,{children:"$\\eta_1$"})," should always be the index of refraction of the material the light is transmitting ",(0,Ae.jsx)("i",{children:"from"})," and ",(0,Ae.jsx)(he.A,{children:"$\\eta_2$"})," that of the material transmitting ",(0,Ae.jsx)("i",{children:"into"}),". Typically, we only consider cases of refraction where one material is air. The refractive index of air is 1.0003, which can be approximated as 1, making refractive index calculations a lot nicer under this assumption. Lastly, total internal reflection must be considered as it causes the expression within the square root to become negative. Therefore the enclosed expressed should be checked for negativity beforehand. Figure 6 shows spheres with varying indices of refraction."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:2e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:z,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Hollow dielectric sphere ",(0,Ae.jsx)(he.A,{children:"$(\\eta_2=1.0)$"})]})}),(0,Ae.jsx)(me.A,{preview:!1,src:M,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Refraction only sphere ",(0,Ae.jsx)(he.A,{children:"$(\\eta_2=1.1)$"})]})}),(0,Ae.jsx)(me.A,{preview:!1,src:L,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Refraction only sphere ",(0,Ae.jsx)(he.A,{children:"$(\\eta_2=1.3)$"})]})}),(0,Ae.jsx)(me.A,{preview:!1,src:E,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Refraction only sphere ",(0,Ae.jsx)(he.A,{children:"$(\\eta_2=1.5)$"})]})}),(0,Ae.jsx)(me.A,{preview:!1,src:H,annotation:(0,Ae.jsxs)(Ae.Fragment,{children:["Refraction only sphere ",(0,Ae.jsx)(he.A,{children:"$(\\eta_2=1.7)$"})]})})]}),(0,Ae.jsxs)("p",{children:["Refraction alone isn't quite the full picture though. Dielectrics are materials which both reflect ",(0,Ae.jsx)("i",{children:"and"})," refract. Common real-life examples are glass and water surfaces. It is not immediately obvious that this is the case - but with a keen eye one can notice that both water and glass become mirror-like at oblique viewing angles. The formal name for this effect is the 'Fresnel effect' - it formally describes the ratio of reflectivity (reflection) against transmittance (refraction) as a function of viewing angle (angle of incidence). The equation to compute this ratio given ",(0,Ae.jsx)(he.A,{children:"$\\omega_i$"})," is quite complex (to look at, and computationally), so instead Schlick's approximation, a cheap yet relatively accurate approximation, can be used:"]}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$R=R_0+(1 - R_0)(1-\\textbf n \\cdot \\omega_i)^5 \\ \\ \\ \\text{where } R_0=\\bigg(\\displaystyle\\frac{\\eta_1-\\eta_2}{\\eta_1 + \\eta_2}\\bigg)^2$"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)("p",{children:["The reflectivity and transmittance act as coefficients for the gathered radiance from the cast specular rays. It should also be noted that as reflectivity and transmittance are in a ratio with one another, ",(0,Ae.jsx)(he.A,{children:"$T = 1-R$"}),". The full Fresnel term is also included for completeness, and is more accurate at the cost of render time. A comparison is shown below."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:3e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"2048px"},children:[(0,Ae.jsx)(me.A,{src:F,annotation:"Example dielectric sphere rendered with full Fresnel effect (left) and its reflectivity visualised (right)."}),(0,Ae.jsx)(me.A,{src:P,annotation:"Example dielectric sphere rendered with Schlick Approximation (left) and its reflectivity visualised (right)."})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"distributed-raytracing",className:"raleway-title",children:"Distributed Raytracing and Emissive Materials"}),(0,Ae.jsxs)("p",{children:["Up until this point, we have only been able to render hard-shadows. This is a consequence of using only point lights and a single occlusion raycast. We had previously seen the term ",(0,Ae.jsx)(he.A,{children:"$L_e$"})," in the rendering equation which implies that instead of using just point lights, we can make objects themselves into light sources. To support emissive materials, we need to change the occlusion calculation to consider percentage occlusion instead of being a boolean calculation. Emissive materials mean our lights have ",(0,Ae.jsx)("b",{children:"area"}),", and this is where soft shadows come from, i.e. these regions soft shadow regions are regions of ",(0,Ae.jsx)("i",{children:"partial"})," light occlusion.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"To calculate partial occlusion, we can use random sampling. When testing for occlusion, we sample ",(0,Ae.jsx)(he.A,{children:"$n$"})," random points on an emissive material's surface, and perform a boolean occlusion test on each one. The arithmetic mean of these tests then gives the proportion of occlusion. We therefore need a method for generating random points on an object's surface, which is usually similar to the uv-mapping calculating, but in reverse.  The use of random sampling also introduces noise, so we should be sure to use as high ",(0,Ae.jsx)(he.A,{children:"$n$"}),"  as possible."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:2e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"1370px"},children:[(0,Ae.jsx)(me.A,{src:U,annotation:"Shadows rendering with only 1 deterministic ray (no distributed raytracing)."}),(0,Ae.jsx)(me.A,{src:S,annotation:"Shadows rendered with 5 sample rays."}),(0,Ae.jsx)(me.A,{src:G,annotation:"Shadows rendered with 10 sample rays."}),(0,Ae.jsx)(me.A,{src:W,annotation:"Shadows rendered with 25 sample rays."}),(0,Ae.jsx)(me.A,{src:V,annotation:"Shadows rendered with 50 sample rays."}),(0,Ae.jsx)(me.A,{src:Z,annotation:"Shadows rendered with 100 sample rays."}),(0,Ae.jsx)(me.A,{src:K,annotation:"Shadows rendered with 200 sample rays."})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"ssaa",className:"raleway-title",children:"Super-Sampling Anti-Aliasing (SSAA)"}),(0,Ae.jsxs)("p",{children:["Aliasing arises from rendering our continuous 3D scene in a limited number of discrete pixels. This is particularly noticeable at object boundaries and where we have diagonal lines.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"There are a number of anti-aliasing techniques that we can employ, but the simplest by far is Super-Sampling Anti-Aliasing (SSAA), and works well for reasonably high resolution images. We generate ",(0,Ae.jsx)(he.A,{children:"$n$"})," rays for each pixel and take the mean colour. Random rays can be generated by taking the principal camera ray and applying a random offset ",(0,Ae.jsx)(he.A,{children:"$\\in[-0.5, 0.5]$"})," in both dimensions of the camera plane. Again, the use of random sampling can introduce noise for low ",(0,Ae.jsx)(he.A,{children:"$n$"}),", so it is best to use as high ",(0,Ae.jsx)(he.A,{children:"$n$"})," as possible.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"SSAA is quite expensive. With each new sample ray we effectively render the whole image once again. If a faster technique is desired, I would suggest having a look at FXAA."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:2e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:"data:image/png;base64,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",annotation:"Sharp cube edge rendered with no SSAA."}),(0,Ae.jsx)(me.A,{preview:!1,src:X,annotation:"Sharp cube edge rendered with 5x SSAA."}),(0,Ae.jsx)(me.A,{preview:!1,src:J,annotation:"Sharp cube edge rendered with 10x SSAA."}),(0,Ae.jsx)(me.A,{preview:!1,src:Y,annotation:"Sharp cube edge rendered with 25x SSAA."}),(0,Ae.jsx)(me.A,{preview:!1,src:ee,annotation:"Sharp cube edge rendered with 50x SSAA."})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"photon-map",className:"raleway-title",children:"Photon Mapping"}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:3e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:te,annotation:"Cornell box rendered with direct illumination only."}),(0,Ae.jsx)(me.A,{preview:!1,src:ie,annotation:"Cornell box rendered with global illumination."})]}),(0,Ae.jsxs)("p",{children:["Photon mapping is a two pass algorithm which allows ",(0,Ae.jsx)(he.A,{children:"$L_i$"})," to be approximated by first bouncing photons around a scene to closer mimic how light is actually transported. This closer-to-reality representation allows photon mapping to include global illumination in its calculations - more specifically indirect illumination (colour bleeding) and caustics (focussed light). It boasts better time complexity and lower-frequency noise in renders than global illumination algorithms of similar age. This comes at the cost of higher memory use, as photons need to be stored when bouncing them around the scene. For the first pass, we bounce photons about our scene and store them when they hit certain surfaces. For the second pass, during the ray-gathering step, we approximate ",(0,Ae.jsx)(he.A,{children:"L_i"})," at ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," from nearby stored photons."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"photon-trace",className:"raleway-title",children:"Photon Tracing and Storage"}),(0,Ae.jsxs)("p",{children:["Photons are bounced around the scene to emulate real light transport - the process is named photon tracing. Photon tracing starts at light sources in the scene and ends when photons bounce off into the void, or are absorbed by a material, just like how light can be absorbed in reality. Tracing starts at the light and thus photons propagate flux as they are traced, as opposed to backwards ray tracing where radiance is gathered from ray casts.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Photons are stored when they hit certain surfaces. The specific surfaces we target depends on the type of illumination being simulated; we distinguish between specular and diffuse surfaces for example. Caustic photons (specular reflections) are stored separately in a 'Caustic Photon Map' from the rest of the illumination - in a 'Global Photon Map' - as they require more precision. In both cases photons are stored in a KD-tree, an appropriate acceleration structure for computing k-nearest-neighbour (knn) searches which are required for the radiance estimate we will see later."]}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:3e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"600px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:ne,annotation:"Visualisation of global photon map (~1M Photons)."}),(0,Ae.jsx)(me.A,{preview:!1,src:ae,annotation:"Visualisation of caustic photon map (~1M Photons)."})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"photon-scatter",className:"raleway-title",children:"Photon Scattering"}),(0,Ae.jsxs)("p",{children:["Diffuse reflection is re-emittance of light randomly in a hemisphere above ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," - we saw this with lambertian diffuse materials. We need to be able to compute this in order to properly simulate the bouncing of photons around a scene. A method for getting a random direction in this hemisphere in world space is therefore required for photon tracing with diffuse surfaces. A random direction in the hemisphere in tangent space (local about ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," with the ",(0,Ae.jsx)(he.A,{children:"$y$"})," basis vector being ",(0,Ae.jsx)(he.A,{children:"$\\textbf n$"}),") can be calculated by generating a random spherical coordinate with ",(0,Ae.jsx)(he.A,{children:"$\\displaystyle\\phi\\in\\bigg[-\\frac{\\pi}{2}, \\frac{\\pi}{2}\\bigg],$"})," ",(0,Ae.jsx)(he.A,{children:"$\\theta\\in[0,2\\pi]$"}),". The spherical coordinate is then transformed into a Cartesian coordinate (still in tangent space), then transformed into world space via an affine transformation."]}),(0,Ae.jsx)("div",{className:"code-snippet",style:{width:"100%"},children:(0,Ae.jsx)(l.A,{language:"cpp",showLineNumbers:!0,style:h.A,startingLineNumber:0,children:"\nVector UTIL::hemisphere_scatter() {\n    const float u = UTIL::rand_float(0.0f, 0.999999f);\n    const float v = UTIL::rand_float(0.0f, 0.999999f);\n    const float theta = 0.5f * acos(UTIL::clamp(1.0f - 2.0f * u, -1.0f, 1.0f));\n    const float phi   = 2 * M_PI * v;\n    const float cost  = cos(theta);\n\n    return UTIL::spherical_to_cartesian(theta, phi);\n    // ...and conversion to world space when needed outside this function.\n}"})}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"photon-roulette",className:"raleway-title",children:"Russian Roulette"}),(0,Ae.jsxs)("p",{children:["Russian roulette is a optimisation technique that can be applied to photon tracing to reduce the computational effort expended on unuseful photons. When we refer to 'unuseful photons', we mean photons that carry very little contributing colour - in physics, this is the energy they carry or 'flux'. Without Russian roulette, it is likely that photons which have been diffusely reflected a few times would have very low flux (as they propagate flux with each bounce). Thus, a lot of effort is wasted in simulating further bounces of these photons which negligibly contribute to the overall lighting. Russian roulette takes a different approach in an attempt to make all photons have similar magnitudes of flux, thus minimising 'wasted' computation time.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"The way Russian roulette works here is through the observation that reflecting ",(0,Ae.jsx)(he.A,{children:"$n$"})," photons at say, 50% power, is equivalent to reflecting ",(0,Ae.jsx)(he.A,{children:"$\\displaystyle\\frac{n}{2}$"})," photons at 100% power. This can be achieved stochastically; A random variable ",(0,Ae.jsx)(he.A,{children:"$\\epsilon\\in[0, 1]$"})," is taken, and compared to the average reflection coefficients of the material ",(0,Ae.jsx)(he.A,{children:"$\\bar\\rho_d, \\bar\\rho_s$"}),", taken from the material's diffuse and specular albedo by averaging their 3 colour channels. The type of reflection is then determined as follows:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\begin{aligned}\n                            \\epsilon\\in[0,\\bar\\rho_d]&\\to\\text{diffuse reflection}\\\\\n                            \\epsilon\\in[0, \\bar\\rho_d+\\bar\\rho_s]&\\to\\text{specular reflection}\\\\\n                            \\epsilon\\in[\\bar\\rho_d+\\bar\\rho_s, 1]&\\to\\text{absorption}\n                        \\end{aligned}$"})})]}),(0,Ae.jsxs)("p",{children:["Note a full BRDF calculation is not used at bounces using this method, instead the flux of reflected photons must be adjusted by multiplying by ",(0,Ae.jsx)(he.A,{children:"$\\rho_d/\\bar\\rho_d$"})," or ",(0,Ae.jsx)(he.A,{children:"$\\rho_s/\\bar\\rho_s$"})," depending on the type of reflection. (i.e. we scale by the colours which would be sampled from the BRDF).",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Overall, we can simulate the effect of more photons with a smaller selection by using russian roulette, so it is a worthwhile optimisation considering we may want to fire millions of photons into our scene."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h2",{id:"photon-gather",className:"raleway-title",children:"Radiance Gathering"}),(0,Ae.jsxs)(a.A,{autoplay:!0,autoplaySpeed:5e3,effect:"fade",style:{margin:"0 auto",paddingBottom:"20px",width:"100%",maxWidth:"512px"},children:[(0,Ae.jsx)(me.A,{preview:!1,src:le,annotation:"All illumination combined: global illumination"}),(0,Ae.jsx)(me.A,{preview:!1,src:re,annotation:"Direct illumination"}),(0,Ae.jsx)(me.A,{preview:!1,src:se,annotation:"Indirect illumination (diffuse)"}),(0,Ae.jsx)(me.A,{preview:!1,src:oe,annotation:"Specular and Glossy"}),(0,Ae.jsx)(me.A,{preview:!1,src:ce,annotation:"Indirect illumination (caustics)"})]}),(0,Ae.jsxs)("p",{children:["Once we have our photon maps, we can begin rendering our final image. This involves calculating the ",(0,Ae.jsx)(he.A,{children:"$L_i(\\textbf x, \\omega_i)$"})," component of the rendering equation. The original implementation of photon mapping proposes splitting the different types of illumination in the scene into separate calculations. The main benefit of this is that we get to use different techniques for each lighting calculation as we see fit, and makes it easier to not double up on simulated light paths.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$L_i(\\textbf x, \\omega_i)=L_{i,l}(\\textbf x, \\omega_i)+(L_{i,c}(\\textbf x, \\omega_i)+L_{i,d}(\\textbf x, \\omega_i))+L_{i,c}(\\textbf x, \\omega_i)+L_{i,d}(\\textbf x, \\omega_i)$"})}),(0,Ae.jsx)("br",{}),"where"]}),(0,Ae.jsxs)("div",{style:{paddingLeft:"2vw",paddingRight:"2vw"},children:[(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"1. "})," \xa0\xa0\xa0"]}),(0,Ae.jsxs)(o.A,{className:"project-style-cont",flex:"1vw",children:[(0,Ae.jsx)(he.A,{children:"$L_{i,l}$"})," - ",(0,Ae.jsx)("b",{children:"Direct Illumination"})," given by ",(0,Ae.jsx)(he.A,{children:"$LDE$"})," in path notation and is directly gathered using standard gathering rays."]})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"2. "})," \xa0\xa0\xa0"]}),(0,Ae.jsxs)(o.A,{className:"project-style-cont",flex:"1vw",children:[(0,Ae.jsx)(he.A,{children:"$L_{i,d}$"})," - ",(0,Ae.jsx)("b",{children:"Indirect Illumination"})," given by ",(0,Ae.jsx)(he.A,{children:"$LD(S|D)+DE$"})," in path notation and is approximated using the global photon map."]})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"3. "})," \xa0\xa0\xa0"]}),(0,Ae.jsxs)(o.A,{className:"project-style-cont",flex:"1vw",children:[(0,Ae.jsx)(he.A,{children:"$L_{i,c}+L_{i,d}$"})," - ",(0,Ae.jsx)("b",{children:"Specular and Glossy "})," given by ",(0,Ae.jsx)(he.A,{children:"$L(S|D)^*SE$"})," in path notation and is again directly gathered using standard gathering rays."]})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"4. "})," \xa0\xa0\xa0"]}),(0,Ae.jsxs)(o.A,{className:"project-style-cont",flex:"1vw",children:[(0,Ae.jsx)(he.A,{children:"$L_{i,c}$"})," - ",(0,Ae.jsx)("b",{children:"Caustics "})," given by ",(0,Ae.jsx)(he.A,{children:"$LS+DE$"})," in path notation and is approximated using the caustic photon map."]})]})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("h3",{id:"li-approx",className:"raleway-title",children:"Incident Radiance Approximation"}),(0,Ae.jsxs)("p",{children:[(0,Ae.jsx)(he.A,{children:"$L_i$"})," can be approximated from a photon map by calculating the flux density of photons in a sphere ",(0,Ae.jsx)(he.A,{children:"$r$"})," about ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),". The radius of the sphere can be a pre-defined constant, leading to a smoother radiance estimate over larger distances, or dynamically calculated by expanding the sphere until a set number of photons are found. The former approach has the effect of smoothing the radiance estimate over larger distances which is useful for indirect illumination (global photon map); the latter approach preserves all the detail in the photon map leading to higher-frequency detail, useful for rendering caustics (caustic photon map). This is why photons are stored in a KD-tree, as it makes it very easy to get all photons in a shere about a point - a simple k-nearest-neighbours query. I won't go over the derivation here, but formally, this estimate transforms the rendering equation into the following:",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)("div",{style:{paddingLeft:"3em",paddingRight:"3em",textAlign:"center"},children:(0,Ae.jsx)(he.A,{children:"$\\displaystyle L_r(\\textbf{x}, \\omega_i, \\omega_r) =\n                        \\frac{1}{\\pi r^2}\\sum_{p=1}^n f_r(\\textbf{x}, \\omega_i, \\omega_r)\\Delta\\Phi_p(\\textbf x, \\omega_i)$"})}),(0,Ae.jsx)("br",{}),"where ",(0,Ae.jsx)(he.A,{children:"$\\Phi_p$"})," are photons from the knn query of the photon map. The main thing of note here is that we calculate the density by assuming the surface around ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"})," is a flat surface - i.e. a circle not a sphere. This gives rise to the divisor of ",(0,Ae.jsx)(he.A,{children:"$\\pi r^2$"}),". It is also worth noting that a sphere is not the most accurate approximation under this assumption - an ellipsoid squished in the direction of ",(0,Ae.jsx)(he.A,{children:"$\\textbf x$"}),"'s normal would be more accurate, but using a sphere has the benefit of being quickly queried from the photon maps."]}),(0,Ae.jsx)("br",{}),(0,Ae.jsx)(r.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}}),(0,Ae.jsx)("h1",{id:"post-process",className:"raleway-title",children:"Post Processing"}),(0,Ae.jsx)("p",{children:"Now that we have rendered out our 3D scene, what's left is to post-process the image to get a final render. At this stage, it is useful to be able to mess with some properties of our image to make it more appealing."}),(0,Ae.jsx)("h2",{id:"post-filters",className:"raleway-title",children:"Basic Image Filters"}),(0,Ae.jsx)("p",{children:"We can build a simple but useful selection of image filters:"}),(0,Ae.jsxs)("div",{style:{paddingLeft:"2vw",paddingRight:"2vw"},children:[(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"1. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{exposure}(\\textbf v,\\ e)=\\textbf v\\cdot e$"})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"2. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{contrast}(\\textbf v,\\ c)=c(\\textbf v - 0.5) + 0.5$"})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"3. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{brightness}(\\textbf v,\\ b)=\\textbf v + b$"})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"4. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{saturation}(\\textbf v,\\ s)=\\text{lerp}(\\textbf v,\\ \\text{gray}(\\textbf v),\\ s)$"})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"5. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{colour overlay}(\\textbf v,\\ \\textbf c)=\\textbf v \\cdot \\textbf c$"})})]}),(0,Ae.jsx)("br",{}),(0,Ae.jsxs)(s.A,{className:"project-style-cont",style:{display:"flex"},children:[(0,Ae.jsxs)(o.A,{className:"project-style-cont",children:[(0,Ae.jsx)("b",{children:"6. "})," \xa0\xa0\xa0"]}),(0,Ae.jsx)(o.A,{className:"project-style-cont",flex:"1vw",children:(0,Ae.jsx)(he.A,{children:"$\\text{gamma}(\\textbf v, \\gamma)=\\textbf v ^ \\gamma$"})})]}),(0,Ae.jsx)("br",{})]}),(0,Ae.jsxs)("p",{children:["It is important to clamp the results of these calculations to be greater than zero - we can't have a negative amount of light! These filters can be applied in any order, except for the gamma space calculation, which ",(0,Ae.jsx)("i",{children:"must"})," be the final post processing step, even after tone mapping which we will visit next. Many more filters exist that we could apply here as well, but this selection is analogous to the kinds of settings you might find on a digital camera."]}),(0,Ae.jsx)("h2",{id:"tone-map",className:"raleway-title",children:"HDR and Tone Mapping"}),(0,Ae.jsxs)("p",{children:["Dynamic Range refers to the range of colours we can represent within our image. Up until this point, renders from a raytracer will be unbounded in terms of colour. We simply add up all of the reflected radiance and store it in our image buffer. Our image therefore is one of ",(0,Ae.jsx)("i",{children:"High Dynamic Range"})," (HDR) - we have values outside of standard RGB representation. We still wish to display our image in RGB though, so we must do a conversion from HDR to RGB space.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"There are various ways of doing this conversion. The most simple method would be to define an exposure cap, like in a digital camera. Any values above our exposure cap are clamped to the cap value ",(0,Ae.jsx)(he.A,{children:"$\\in[0, 255]$"})," in RGB images. We could extend this exposure cap to be automatic by stretching or compressing our range of values to ",(0,Ae.jsx)(he.A,{children:"$[0, 255]$"})," in a similar fashion to a contrast filter. These filters would work fine for a realistic conversion, but we aren't making use of the HDR information we have.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"Tonemapping makes use of HDR information by mapping HDR colour values to a curve, properly balancing the light levels and also letting us apply a certain level of artistic effect. It is basically a variable colour filter, allowing our images to have a certain 'feel' under the curve. For example, we could make images have a yellowish tint in their mid-tones for a more cosy feel.",(0,Ae.jsx)("br",{}),(0,Ae.jsx)("br",{}),"There are many tonemapping curves, a popular choice in video games is the ACES curve. In this implementation, I use a curve made by Hajime Uchimura, the details of which can be found ",(0,Ae.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://www.polyphony.co.jp/publications/sa2018/",children:"here"}),"."]})]})}},92026:(e,t,i)=>{i.d(t,{A:()=>r});i(27565);var n=i(45577),a=i(27929);const r=e=>{let{annotation:t,fontSize:i,...r}=e;const s=r.paddingBottom?r.paddingBottom:"20px";return(0,a.jsxs)("div",{style:{position:"relative"},children:[(0,a.jsx)(n.A,{...r}),t?(0,a.jsx)("div",{className:"styled-text",style:{position:"absolute",bottom:0,left:0,backgroundColor:"rgba(21, 25, 31, 0.65)",width:"100%",fontSize:i&&i,textAlign:"center",padding:"10px 5px",paddingBottom:s},children:t}):null]})}},58990:(e,t,i)=>{i.d(t,{A:()=>d});var n=i(27565),a=i(11030),r=i(20477),s=i(58860),o=i(46761),c=i(75342),l=i(85477),h=(i(29780),i(27929));const d=e=>{let{title:t,githubURL:i,projectRoute:d,projectLink:p,thumb:m}=e;const A=(0,a.zy)().pathname;return(0,n.useEffect)((()=>{window.scrollTo(0,0)}),[]),(0,h.jsxs)(h.Fragment,{children:[(0,h.jsx)("div",{style:{marginTop:"-3rem",backgroundImage:"url(".concat(m,")"),backgroundPosition:"center",backgroundSize:"cover",backgroundRepeat:"no-repeat",height:"100vh",zIndex:-1}}),(0,h.jsxs)("div",{className:"project-home-wrapper",style:{position:"absolute",width:"100%",top:"101vh",left:"0px",transform:"translate(0, -100%)"},children:[(0,h.jsxs)("header",{className:"home-header",children:[(0,h.jsx)("h1",{id:"title",style:{display:"inline-block"},children:t}),(0,h.jsxs)("span",{style:{padding:"0 1em",display:"inline-block"},children:[void 0!=i?(0,h.jsx)(s.A,{title:"View on Github",placement:"bottom",children:(0,h.jsx)("a",{href:i,target:"_blank",children:(0,h.jsx)(c.A,{className:"title-icon"})})}):null,void 0!=d?(0,h.jsx)(s.A,{title:"View project",placement:"bottom",children:(0,h.jsx)(r.N_,{to:A+d,children:(0,h.jsx)(l.A,{className:"title-icon"})})}):null,void 0!=p?(0,h.jsx)(s.A,{title:"View project",placement:"bottom",children:(0,h.jsx)("a",{href:p,target:"_blank",children:(0,h.jsx)(l.A,{className:"title-icon"})})}):null]}),(0,h.jsx)(o.A,{style:{borderTopWidth:"1px",borderTopColor:"#000000",opacity:.5}})]}),(0,h.jsx)("div",{style:{height:"8em"}})]})]})}},95569:(e,t,i)=>{i.d(t,{A:()=>g});var n=i(28370),a=i.n(n),r=i(58990),s=i(65894),o=i(9514),c=i(27565),l=i(27929);const h=e=>{var t=e.filter((e=>{let t=e.nodeName;return"title"!==e.id&&("H1"===t||"H2"===t||"H3"===t)}));let i=-1;var n=t.map((e=>(i++,{key:"contents_".concat(i),href:"#".concat(e.id),title:e.innerHTML,level:parseInt(e.nodeName.slice(-1))}))),a=[],r=[],s=[a];return n.forEach((e=>{var t=r.findIndex((t=>t>=e.level));-1===t?t=r.push(e.level)-1:r.length=t+1,s[t].push(Object.assign({},e,{children:s[t+1]=[]}))})),a},d=e=>{let{title:t}=e;const{nestedHeadings:i}=(()=>{const[e,t]=(0,c.useState)([]);return(0,c.useEffect)((()=>{const e=Array.from(document.querySelectorAll("h1, h2, h3")),i=h(e);t(i)}),[]),{nestedHeadings:e}})(),{navHeight:n}=(()=>{const[e,t]=(0,c.useState)(0);return(0,c.useEffect)((()=>{const e=document.getElementById("main-navbar");console.log(e),t(e.offsetHeight)}),[]),{navHeight:e}})(),[a,r]=(0,c.useState)("85vh");return(0,c.useEffect)((()=>{const e=document.getElementById("toc-breadcrumb");e&&r("calc(100vh - 6rem - ".concat(e.offsetHeight,"px)"))}),[]),(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(s.A,{id:"toc-breadcrumb",style:{paddingBottom:"14px",position:"sticky"},items:[{title:(0,l.jsx)("a",{href:"#home",children:"Portfolio"})},{title:(0,l.jsx)("a",{href:"#projects",children:"Projects"})},{title:"".concat(t)}]}),(0,l.jsx)(o.A,{style:{maxHeight:a,overflow:"auto"},targetOffset:n,onClick:(e,t)=>{e.preventDefault()},items:i})]})};var p=i(50899),m=i(20791),A=i(39432);const{useBreakpoint:f}=p.Ay,g=e=>{let{title:t,thumb:i,projectLink:n,projectRoute:s,githubURL:o,footer:c,children:h}=e;const p=f();return(0,l.jsx)(l.Fragment,{children:(0,l.jsxs)(a(),{children:[(0,l.jsx)(r.A,{title:t,thumb:i,projectRoute:s,projectLink:n,githubURL:o}),(0,l.jsxs)(m.A,{gutter:0,children:[(0,l.jsx)(A.A,{xs:0,lg:5,children:(0,l.jsx)("div",{className:"project-toc-wrapper",children:(0,l.jsx)(d,{title:t})})}),(0,l.jsxs)(A.A,{xs:24,lg:19,children:[(0,l.jsx)("div",{className:"project-content-wrapper",style:{marginRight:p.lg?"17.5vw":"6vw",marginLeft:p.lg?0:"6vw"},children:h}),(0,l.jsx)("div",{className:"project-footer-wrapper",style:{display:"flex",justifyContent:"center",marginTop:"8vh",marginBottom:"5vh",marginRight:p.lg?"17.5vw":"6vw",marginLeft:p.lg?0:"6vw"},children:c?{footer:c}:"\u274b That's all! Thanks for reading. \u274b"})]})]})]})})}},29780:()=>{}}]);
//# sourceMappingURL=962.3892ef9a.chunk.js.map